{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b300e-47e8-4f50-8c92-c8ea0791f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Full pipeline script (training optional + post-processing priority + SHAP)\n",
    "- Set FORCE_TRAIN=True on first run to generate preprocessor/weights/parameters/assets.\n",
    "- Afterwards set FORCE_TRAIN=False to perform only post-processing and explanation.\n",
    "- When DATA_PATH, feature slices, MONO_MODE, hyperparameters, etc. change,\n",
    "  the script will detect the difference and retrain once to ensure consistency.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    mean_absolute_error,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# ===================== Basic Configuration (modify as needed) =====================\n",
    "# Data / Output paths (example uses GI dataset)\n",
    "DATA_PATH = \"./data/extracted_Gradually_Increasing.csv\"  # Replace with other datasets (e.g. FD), but adjust slices & monotonic direction\n",
    "OUT_DIR   = \"./results/Gradually_Increasing\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Set True on first run to save assets; False afterwards for post-processing & explanation only\n",
    "FORCE_TRAIN = False\n",
    "\n",
    "# Feature column slices (GI: 9:417; FD: 9:76)\n",
    "PROTEIN_SLICE   = slice(9, 417)     # GI\n",
    "COVARIATE_SLICE = slice(2, 9)\n",
    "\n",
    "# Monotonic direction: FD → \"dec\" (higher protein → milder condition), GI → \"inc\" (higher → worse)\n",
    "MONO_MODE = \"inc\"                   # GI\n",
    "\n",
    "# Model & training hyperparameters\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "NUM_CLASSES = 5\n",
    "TAU = 3.5\n",
    "SIGMA_LDL = 1.2\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS_GS  = 120\n",
    "EPOCHS_FIN = 120\n",
    "N_ENSEMBLE = 3\n",
    "\n",
    "# Combined objective weights (overall quality dominant; middle classes recall has small weight)\n",
    "OBJ_WEIGHTS = dict(acc=0.45, qwk=0.35, macro=0.10, midrec=0.10)\n",
    "\n",
    "# ===================== File Paths (cache / assets) =====================\n",
    "VAL_PROBS_NPY  = os.path.join(OUT_DIR, \"cache_val_probs.npy\")\n",
    "TEST_PROBS_NPY = os.path.join(OUT_DIR, \"cache_test_probs.npy\")\n",
    "VAL_Y_NPY      = os.path.join(OUT_DIR, \"cache_val_y.npy\")\n",
    "TEST_Y_NPY     = os.path.join(OUT_DIR, \"cache_test_y.npy\")\n",
    "BEST_SEL_JSON  = os.path.join(OUT_DIR, \"best_selection.json\")\n",
    "\n",
    "PREPROC_DIR    = os.path.join(OUT_DIR, \"preproc\")\n",
    "os.makedirs(PREPROC_DIR, exist_ok=True)\n",
    "IMP_P_PKL      = os.path.join(PREPROC_DIR, \"imp_p.pkl\")\n",
    "IMP_C_PKL      = os.path.join(PREPROC_DIR, \"imp_c.pkl\")\n",
    "SC_P_PKL       = os.path.join(PREPROC_DIR, \"sc_p.pkl\")\n",
    "SC_C_PKL       = os.path.join(PREPROC_DIR, \"sc_c.pkl\")\n",
    "\n",
    "MODEL_PARAMS_JSON = os.path.join(OUT_DIR, \"best_model_params.json\")\n",
    "ENS0_WEIGHTS_H5   = os.path.join(OUT_DIR, \"ens0.weights.h5\")\n",
    "\n",
    "IDX_DIR       = os.path.join(OUT_DIR, \"indices\")\n",
    "os.makedirs(IDX_DIR, exist_ok=True)\n",
    "IDX_TRAIN_NPY = os.path.join(IDX_DIR, \"idx_train.npy\")\n",
    "IDX_VAL_NPY   = os.path.join(IDX_DIR, \"idx_val.npy\")\n",
    "IDX_TEST_NPY  = os.path.join(IDX_DIR, \"idx_test.npy\")\n",
    "\n",
    "FEATURE_NAMES_JSON = os.path.join(OUT_DIR, \"feature_names.json\")\n",
    "META_JSON    = os.path.join(OUT_DIR, \"cache_meta.json\")\n",
    "\n",
    "# ===================== Utility Functions =====================\n",
    "def display_pred_dist(name, y):\n",
    "    u, c = np.unique(y, return_counts=True)\n",
    "    print(name, dict(zip(u, c)))\n",
    "\n",
    "def gaussian_label_distribution(y, C, sigma=1.2):\n",
    "    y = y.astype(np.float32)\n",
    "    ks = np.arange(C, dtype=np.float32)[None, :]\n",
    "    yi = y[:, None]\n",
    "    T = np.exp(-(ks - yi)**2 / (2.0 * (sigma**2)))\n",
    "    T = T / (T.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    return T.astype(np.float32)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred, C=5):\n",
    "    W = np.zeros((C, C), dtype=np.float64)\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            W[i, j] = ((i - j) / (C - 1)) ** 2\n",
    "    CM = np.zeros((C, C), dtype=np.float64)\n",
    "    for a, b in zip(y_true, y_pred):\n",
    "        CM[a, b] += 1\n",
    "    n = CM.sum()\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    O = CM / n\n",
    "    hist_true = O.sum(axis=1)\n",
    "    hist_pred = O.sum(axis=0)\n",
    "    E = np.outer(hist_true, hist_pred)\n",
    "    denom = (W * E).sum() + 1e-12\n",
    "    return 1.0 - (W * O).sum() / denom\n",
    "\n",
    "def softmax_power(p, gamma):\n",
    "    p = np.clip(p, 1e-8, 1.0)\n",
    "    z = p ** gamma\n",
    "    return z / (z.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def digitize_with_cuts(ey, cuts):\n",
    "    bins = [-np.inf] + list(cuts) + [np.inf]\n",
    "    return np.digitize(ey, bins) - 1\n",
    "\n",
    "def combo_objective(y_true, y_pred, weights=OBJ_WEIGHTS):\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    qwk   = quadratic_weighted_kappa(y_true, y_pred, C=NUM_CLASSES)\n",
    "    macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec2  = recall_score(y_true, y_pred, labels=[2], average='macro', zero_division=0)\n",
    "    rec3  = recall_score(y_true, y_pred, labels=[3], average='macro', zero_division=0)\n",
    "    midrec = 0.5 * (rec2 + rec3)\n",
    "    obj = (weights['acc']   * acc +\n",
    "           weights['qwk']   * qwk +\n",
    "           weights['macro'] * macro +\n",
    "           weights['midrec']* midrec)\n",
    "    return obj, acc, qwk, macro, midrec\n",
    "\n",
    "def make_dataset(X, y, T, batch_size, training=True, mixup_alpha=0.3):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, (y, T)))\n",
    "    if training:\n",
    "        ds = ds.shuffle(len(X), seed=RANDOM_STATE, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(batch_size, drop_remainder=training)\n",
    "    if training and mixup_alpha > 0:\n",
    "        def _mix(xs, yts):\n",
    "            ys, Ts = yts\n",
    "            bs = tf.shape(xs)[0]\n",
    "            idx = tf.random.shuffle(tf.range(bs))\n",
    "            lam1 = tf.random.gamma([bs,1], mixup_alpha, beta=1.0)\n",
    "            lam2 = tf.random.gamma([bs,1], mixup_alpha, beta=1.0)\n",
    "            lam  = tf.cast(lam1 / (lam1 + lam2), tf.float32)\n",
    "            xs2, Ts2 = tf.gather(xs, idx, axis=0), tf.gather(Ts, idx, axis=0)\n",
    "            xs_m  = lam * xs + (1 - lam) * xs2\n",
    "            Ts_m  = lam * Ts + (1 - lam) * Ts2\n",
    "            return xs_m, (ys, Ts_m)\n",
    "        ds = ds.map(_mix, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# ===================== Model Definition (monotonic direction switchable) =====================\n",
    "class OrdinalLDL(tf.keras.Model):\n",
    "    def __init__(self, input_dim, num_classes, layer_sizes, dropout_rate,\n",
    "                 l2_lambda, protein_indices,\n",
    "                 tau=TAU,\n",
    "                 ey_lambda=0.8, emd_lambda=1.0, kl_lambda=1.2,\n",
    "                 entropy_lambda=0.10, score_l2_lambda=1.0e-3,\n",
    "                 mono_lambda=5e-4, alpha_margin=0.5, margin_lambda=2e-2,\n",
    "                 train_prior=None, gaussian_noise_std=0.01, mono_mode=\"inc\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.tau = tf.constant(tau, tf.float32)\n",
    "        self.mono_mode = mono_mode  # \"dec\" / \"inc\"\n",
    "        self.in_noise = tf.keras.layers.GaussianNoise(gaussian_noise_std)\n",
    "        self.backbone = tf.keras.Sequential(name=\"backbone\")\n",
    "        for s in layer_sizes:\n",
    "            self.backbone.add(tf.keras.layers.Dense(\n",
    "                s, activation='relu',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "            self.backbone.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "        self.score_head = tf.keras.layers.Dense(1, activation=None,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name=\"score\")\n",
    "        self.alpha_raw = tf.Variable(tf.random.normal([num_classes-1], stddev=0.1),\n",
    "                                     trainable=True, name=\"alpha_raw\")\n",
    "        self.protein_indices = tf.constant(protein_indices, dtype=tf.int32)\n",
    "        self.ey_lambda = tf.constant(ey_lambda, tf.float32)\n",
    "        self.emd_lambda = tf.constant(emd_lambda, tf.float32)\n",
    "        self.kl_lambda = tf.constant(kl_lambda, tf.float32)\n",
    "        self.entropy_lambda = tf.constant(entropy_lambda, tf.float32)\n",
    "        self.score_l2_lambda = tf.constant(score_l2_lambda, tf.float32)\n",
    "        self.mono_lambda = tf.constant(mono_lambda, tf.float32)\n",
    "        self.margin_lambda = tf.constant(margin_lambda, tf.float32)\n",
    "        self.alpha_margin  = tf.constant(alpha_margin, tf.float32)\n",
    "        self.train_prior = tf.constant(train_prior, tf.float32) if train_prior is not None else None\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.in_noise(inputs, training=training)\n",
    "        h = self.backbone(x, training=training)\n",
    "        score = self.score_head(h)\n",
    "        return score\n",
    "\n",
    "    def get_alphas(self):\n",
    "        inc = tf.nn.softplus(self.alpha_raw) + 1e-6\n",
    "        alpha = tf.cumsum(inc)\n",
    "        alpha = alpha - tf.reduce_mean(alpha)\n",
    "        return alpha\n",
    "\n",
    "    def class_probs_from_score(self, score, alpha):\n",
    "        logits = (score - alpha[tf.newaxis, :]) / self.tau\n",
    "        probs_gt = tf.sigmoid(logits)               # P(y > k)\n",
    "        p0 = 1 - probs_gt[:, :1]\n",
    "        p_mid = probs_gt[:, :-1] - probs_gt[:, 1:] if probs_gt.shape[1] > 1 else tf.zeros((tf.shape(score)[0], 0), score.dtype)\n",
    "        plast = probs_gt[:, -1:]\n",
    "        p = tf.concat([p0, p_mid, plast], axis=1)\n",
    "        p = tf.clip_by_value(p, 1e-7, 1.0)\n",
    "        p = p / tf.reduce_sum(p, axis=1, keepdims=True)\n",
    "        return p\n",
    "\n",
    "    @staticmethod\n",
    "    def _cumdist(p):  # (n, C)\n",
    "        return tf.cumsum(p, axis=1)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, (y_int, T_soft) = data\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        y_int = tf.cast(tf.reshape(y_int, (-1,1)), tf.float32)\n",
    "        T_soft = tf.cast(T_soft, tf.float32)\n",
    "        with tf.GradientTape() as tape_params:\n",
    "            with tf.GradientTape() as tape_x:\n",
    "                tape_x.watch(x)\n",
    "                score = self(x, training=True)\n",
    "                alpha = self.get_alphas()\n",
    "                p = self.class_probs_from_score(score, alpha)\n",
    "                classes = tf.cast(tf.range(self.num_classes), tf.float32)[tf.newaxis,:]\n",
    "                ey = tf.reduce_sum(p * classes, axis=1, keepdims=True)\n",
    "\n",
    "                CE = -tf.reduce_mean(tf.reduce_sum(T_soft * tf.math.log(p + 1e-8), axis=1))\n",
    "                Ft = self._cumdist(T_soft)\n",
    "                Fp = self._cumdist(p)\n",
    "                EMD2 = tf.reduce_mean(tf.reduce_sum(tf.square(Fp - Ft), axis=1))\n",
    "                MSE_ey = tf.reduce_mean(tf.square(ey - y_int))\n",
    "                KL = 0.0\n",
    "                if self.train_prior is not None:\n",
    "                    mean_pred = tf.reduce_mean(p, axis=0)\n",
    "                    KL = tf.reduce_sum(mean_pred * (tf.math.log(mean_pred + 1e-8) - tf.math.log(self.train_prior + 1e-8)))\n",
    "                Ent = -tf.reduce_mean(tf.reduce_sum(p * tf.math.log(p + 1e-8), axis=1))\n",
    "\n",
    "                score_mean = tf.reduce_mean(score)\n",
    "                grads_x = tape_x.gradient(score_mean, x)\n",
    "                prot_grads = tf.gather(grads_x, indices=self.protein_indices, axis=1)\n",
    "                if self.mono_mode == \"dec\":\n",
    "                    mono_pen = tf.reduce_mean(tf.nn.relu(prot_grads)**2)\n",
    "                else:\n",
    "                    mono_pen = tf.reduce_mean(tf.nn.relu(-prot_grads)**2)\n",
    "\n",
    "                deltas = alpha[1:] - alpha[:-1]\n",
    "                margin_pen = tf.reduce_mean(tf.nn.relu(self.alpha_margin - deltas)**2)\n",
    "                score_l2 = tf.reduce_mean(tf.square(score))\n",
    "                reg_loss = tf.add_n(self.losses) if self.losses else 0.0\n",
    "\n",
    "                loss = (CE + self.emd_lambda*EMD2 + self.ey_lambda*MSE_ey + self.kl_lambda*KL\n",
    "                        - self.entropy_lambda*Ent + self.mono_lambda*mono_pen\n",
    "                        + self.margin_lambda*margin_pen + self.score_l2_lambda*score_l2 + reg_loss)\n",
    "\n",
    "        grads = tape_params.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        y_pred = tf.argmax(p, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(y_pred, tf.cast(y_int, tf.int32)), tf.float32))\n",
    "        return {\"loss\": loss, \"accuracy\": acc}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, (y_int, T_soft) = data\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        y_int = tf.cast(tf.reshape(y_int, (-1,1)), tf.float32)\n",
    "        T_soft = tf.cast(T_soft, tf.float32)\n",
    "        score = self(x, training=False)\n",
    "        alpha = self.get_alphas()\n",
    "        p = self.class_probs_from_score(score, alpha)\n",
    "        classes = tf.cast(tf.range(self.num_classes), tf.float32)[tf.newaxis,:]\n",
    "        ey = tf.reduce_sum(p*classes, axis=1, keepdims=True)\n",
    "        CE = -tf.reduce_mean(tf.reduce_sum(T_soft * tf.math.log(p + 1e-8), axis=1))\n",
    "        Ft = self._cumdist(T_soft)\n",
    "        Fp = self._cumdist(p)\n",
    "        EMD2 = tf.reduce_mean(tf.reduce_sum(tf.square(Fp - Ft), axis=1))\n",
    "        MSE_ey = tf.reduce_mean(tf.square(ey - y_int))\n",
    "        y_pred = tf.argmax(p, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(y_pred, tf.cast(y_int, tf.int32)), tf.float32))\n",
    "        return {\"loss\": CE + self.emd_lambda*EMD2 + self.ey_lambda*MSE_ey, \"accuracy\": acc}\n",
    "\n",
    "    def predict_class_probs(self, X):\n",
    "        score = self(X, training=False)\n",
    "        alpha = self.get_alphas()\n",
    "        return self.class_probs_from_score(score, alpha).numpy()\n",
    "\n",
    "def predict_probs_and_ey(model, X, tau=TAU):\n",
    "    score = model(X.astype(np.float32), training=False)\n",
    "    alpha = model.get_alphas()\n",
    "    logits = (score - alpha[tf.newaxis, :]) / tau\n",
    "    probs_gt = tf.sigmoid(logits)\n",
    "    p0 = 1 - probs_gt[:, :1]\n",
    "    p_mid = probs_gt[:, :-1] - probs_gt[:, 1:] if probs_gt.shape[1] > 1 else tf.zeros((tf.shape(score)[0], 0), score.dtype)\n",
    "    plast = probs_gt[:, -1:]\n",
    "    p = tf.concat([p0, p_mid, plast], axis=1).numpy()\n",
    "    p = p / (p.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    ey = (p * np.arange(NUM_CLASSES)[None, :]).sum(axis=1)\n",
    "    return p, ey\n",
    "\n",
    "# ===================== Calibration Search (combined objective + extreme-class friendly) =====================\n",
    "def _precompute_sorted(ey, y):\n",
    "    order = np.argsort(ey)\n",
    "    ey_s = ey[order]\n",
    "    y_s = y[order]\n",
    "    C = NUM_CLASSES\n",
    "    onehot = np.eye(C, dtype=np.int32)[y_s]\n",
    "    cum = np.vstack([np.zeros((1,C), dtype=np.int32), np.cumsum(onehot, axis=0)])\n",
    "    return ey_s, y_s, cum, order\n",
    "\n",
    "def _indices_from_quantiles(ey_s, qs=(0.2, 0.4, 0.6, 0.8)):\n",
    "    n = len(ey_s)\n",
    "    cuts = [np.quantile(ey_s, q) for q in qs]\n",
    "    idxs = [int(np.searchsorted(ey_s, c, side='right')) for c in cuts]\n",
    "    idxs = np.clip(np.maximum.accumulate(idxs), 1, n-1)\n",
    "    return tuple(idxs)\n",
    "\n",
    "def _cd_cutpoints(ey, y, obj_func, max_iter=4, win_frac=0.18, step_frac=0.02, min_gap_frac=0.01):\n",
    "    ey_s, y_s, cum, order = _precompute_sorted(ey, y)\n",
    "    n = len(ey_s)\n",
    "    GAP = max(1, int(min_gap_frac*n))\n",
    "    STEP = max(1, int(step_frac*n))\n",
    "    WIN0 = max(1, int(win_frac*n))\n",
    "    i1,i2,i3,i4 = _indices_from_quantiles(ey_s)\n",
    "\n",
    "    def _eval_from_idxs(i1,i2,i3,i4):\n",
    "        cuts = []\n",
    "        for i in (i1,i2,i3,i4):\n",
    "            left  = ey_s[max(i-1, 0)]\n",
    "            right = ey_s[min(i,   n-1)]\n",
    "            cuts.append(0.5*(left+right))\n",
    "        y_hat = digitize_with_cuts(ey, cuts)\n",
    "        return obj_func(y, y_hat), tuple(cuts)\n",
    "\n",
    "    best_metrics, best_cuts = _eval_from_idxs(i1,i2,i3,i4)\n",
    "    best_obj = best_metrics[0]\n",
    "    win = WIN0\n",
    "    improved = True\n",
    "    it = 0\n",
    "    idxs = [i1,i2,i3,i4]\n",
    "    while improved and it < max_iter:\n",
    "        improved = False\n",
    "        for k in range(4):\n",
    "            lo = (idxs[k-1]+GAP) if k > 0 else 1\n",
    "            hi = (idxs[k+1]-GAP) if k < 3 else (n-1)\n",
    "            lo = max(lo, idxs[k]-win)\n",
    "            hi = min(hi, idxs[k]+win)\n",
    "            best_local = best_obj\n",
    "            best_loc = idxs[k]\n",
    "            best_local_cuts = best_cuts\n",
    "            for idx in range(lo, hi+1, STEP):\n",
    "                cur = idxs.copy()\n",
    "                cur[k] = idx\n",
    "                metrics, cuts = _eval_from_idxs(*cur)\n",
    "                if metrics[0] > best_local:\n",
    "                    best_local = metrics[0]\n",
    "                    best_loc = idx\n",
    "                    best_local_cuts = cuts\n",
    "            if best_local > best_obj + 1e-12:\n",
    "                best_obj = best_local\n",
    "                idxs[k] = best_loc\n",
    "                best_cuts = best_local_cuts\n",
    "                improved = True\n",
    "        win = max(1, int(win*0.7))\n",
    "        it += 1\n",
    "    return best_cuts, best_obj\n",
    "\n",
    "def extreme_objective(y_true, y_pred):\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    rec0  = recall_score(y_true, y_pred, labels=[0], average='macro', zero_division=0)\n",
    "    rec4  = recall_score(y_true, y_pred, labels=[4], average='macro', zero_division=0)\n",
    "    ext   = 0.5 * (rec0 + rec4)\n",
    "    obj = 0.30 * acc + 0.20 * macro + 0.50 * ext\n",
    "    return obj, acc, np.nan, macro, ext\n",
    "\n",
    "def search_calibration_ext(y_val, p_val, weights=OBJ_WEIGHTS):\n",
    "    best = {\"obj\": -1.0}\n",
    "    classes = np.arange(NUM_CLASSES)\n",
    "\n",
    "    # Phase 1: combined objective (γ, a, b → cutpoints)\n",
    "    for g in [0.9, 1.0, 1.1, 1.2]:\n",
    "        p_g  = softmax_power(p_val, g)\n",
    "        ey_g = (p_g * classes[None,:]).sum(axis=1)\n",
    "        a_ls, b_ls = np.polyfit(ey_g, y_val, 1)\n",
    "        a_ls = float(np.clip(a_ls, 0.85, 1.20))\n",
    "        b_ls = float(np.clip(b_ls, -0.30, 0.30))\n",
    "        for a in [a_ls-0.05, a_ls, a_ls+0.05]:\n",
    "            for b in [b_ls-0.10, b_ls, b_ls+0.10]:\n",
    "                ey_ab = a*ey_g + b\n",
    "                def _obj_combo(y_t, y_h): return combo_objective(y_t, y_h, weights)\n",
    "                cuts, _ = _cd_cutpoints(ey_ab, y_val, _obj_combo, max_iter=4)\n",
    "                y_hat = digitize_with_cuts(ey_ab, cuts)\n",
    "                obj, acc, qwk, macro, midrec = combo_objective(y_val, y_hat, weights)\n",
    "                if obj > best[\"obj\"]:\n",
    "                    best = {\n",
    "                        \"obj\": obj, \"acc\": acc, \"qwk\": qwk, \"macro\": macro, \"midrec\": midrec,\n",
    "                        \"mode\": \"cut\", \"gamma\": g, \"a\": a, \"b\": b, \"cuts\": cuts\n",
    "                    }\n",
    "\n",
    "    # Phase 2: extreme-class friendly fine-tuning (around best point)\n",
    "    g0, a0, b0 = best[\"gamma\"], best[\"a\"], best[\"b\"]\n",
    "    best_ext = {\"obj\": -1.0}\n",
    "    for dg in [0.95, 1.0, 1.05]:\n",
    "        for da in [0.95, 1.0, 1.05]:\n",
    "            for db in [-0.10, 0.0, 0.10]:\n",
    "                ey_ab = (a0*da) * ((softmax_power(p_val, g0*dg) * classes[None,:]).sum(axis=1)) + (b0 + db)\n",
    "                cuts, _ = _cd_cutpoints(ey_ab, y_val, extreme_objective, max_iter=3)\n",
    "                y_hat = digitize_with_cuts(ey_ab, cuts)\n",
    "                obj, acc, _, macro, ext = extreme_objective(y_val, y_hat)\n",
    "                if obj > best_ext[\"obj\"]:\n",
    "                    best_ext = {\n",
    "                        \"obj\": obj, \"acc\": acc, \"macro\": macro, \"ext\": ext,\n",
    "                        \"gamma\": g0*dg, \"a\": a0*da, \"b\": b0+db, \"cuts\": cuts\n",
    "                    }\n",
    "\n",
    "    # Replacement condition (mild): ext gain ≥0.06 and acc drop ≤0.02\n",
    "    p_g0 = softmax_power(p_val, best[\"gamma\"])\n",
    "    ey_g0 = (p_g0 * classes[None,:]).sum(axis=1)\n",
    "    y_hat0 = digitize_with_cuts(best[\"a\"]*ey_g0 + best[\"b\"], best[\"cuts\"])\n",
    "    _, _, _, _, ext0 = extreme_objective(y_val, y_hat0)\n",
    "\n",
    "    p_g1 = softmax_power(p_val, best_ext[\"gamma\"])\n",
    "    ey_g1 = (p_g1 * classes[None,:]).sum(axis=1)\n",
    "    y_hat1 = digitize_with_cuts(best_ext[\"a\"]*ey_g1 + best_ext[\"b\"], best_ext[\"cuts\"])\n",
    "    acc1 = accuracy_score(y_val, y_hat1)\n",
    "\n",
    "    if (best_ext[\"ext\"] - ext0 >= 0.06) and (acc1 >= best[\"acc\"] - 0.02):\n",
    "        best = {\n",
    "            \"obj\": best[\"obj\"], \"acc\": acc1,\n",
    "            \"qwk\": quadratic_weighted_kappa(y_val, y_hat1, C=NUM_CLASSES),\n",
    "            \"macro\": f1_score(y_val, y_hat1, average='macro', zero_division=0),\n",
    "            \"midrec\": 0.5 * (\n",
    "                recall_score(y_val, y_hat1, labels=[2], average='macro', zero_division=0) +\n",
    "                recall_score(y_val, y_hat1, labels=[3], average='macro', zero_division=0)\n",
    "            ),\n",
    "            \"mode\": \"cut\",\n",
    "            \"gamma\": best_ext[\"gamma\"],\n",
    "            \"a\": best_ext[\"a\"],\n",
    "            \"b\": best_ext[\"b\"],\n",
    "            \"cuts\": best_ext[\"cuts\"]\n",
    "        }\n",
    "    return best\n",
    "\n",
    "def apply_selection(sel, p_mat):\n",
    "    p_g = softmax_power(p_mat, sel['gamma'])\n",
    "    ey = (p_g * np.arange(NUM_CLASSES)[None,:]).sum(axis=1)\n",
    "    ey = sel['a'] * ey + sel['b']\n",
    "    if sel.get(\"mode\", \"cut\") == \"cut\":\n",
    "        return digitize_with_cuts(ey, sel['cuts'])\n",
    "    else:\n",
    "        return np.rint(sel['iso'].predict(ey)).astype(int).clip(0, NUM_CLASSES-1)\n",
    "\n",
    "# ===================== Cache Fingerprint (meta) & Validity Check =====================\n",
    "meta_now = dict(\n",
    "    data_path=os.path.abspath(DATA_PATH),\n",
    "    protein_slice=repr(PROTEIN_SLICE),\n",
    "    cov_slice=repr(COVARIATE_SLICE),\n",
    "    mono_mode=MONO_MODE,\n",
    "    num_classes=int(NUM_CLASSES),\n",
    "    tau=float(TAU),\n",
    "    random_state=int(RANDOM_STATE),\n",
    ")\n",
    "\n",
    "def assets_exist():\n",
    "    need = [\n",
    "        IMP_P_PKL, IMP_C_PKL, SC_P_PKL, SC_C_PKL,\n",
    "        MODEL_PARAMS_JSON, ENS0_WEIGHTS_H5,\n",
    "        IDX_TRAIN_NPY, IDX_VAL_NPY, IDX_TEST_NPY,\n",
    "        FEATURE_NAMES_JSON\n",
    "    ]\n",
    "    return all(os.path.exists(p) for p in need)\n",
    "\n",
    "ready_in_memory     = all(k in globals() for k in [\"p_val_avg\",\"p_test_avg\",\"y_val\",\"y_test\"])\n",
    "ready_probs_on_disk = all(os.path.exists(p) for p in [VAL_PROBS_NPY, TEST_PROBS_NPY, VAL_Y_NPY, TEST_Y_NPY])\n",
    "ready_assets_on_disk = assets_exist()\n",
    "\n",
    "# Fingerprint gate\n",
    "if ready_probs_on_disk or ready_assets_on_disk:\n",
    "    if not os.path.exists(META_JSON):\n",
    "        print(\"[CACHE] Found old cache but missing meta fingerprint: will ignore cache and retrain.\")\n",
    "        ready_in_memory = ready_probs_on_disk = ready_assets_on_disk = False\n",
    "    else:\n",
    "        meta_old = json.load(open(META_JSON, \"r\", encoding=\"utf-8\"))\n",
    "        if meta_old != meta_now:\n",
    "            print(\"[CACHE] Cache fingerprint does not match current config: ignoring old cache and retraining.\")\n",
    "            ready_in_memory = ready_probs_on_disk = ready_assets_on_disk = False\n",
    "\n",
    "if FORCE_TRAIN:\n",
    "    print(\"[FORCE] Force retraining to generate/update assets and probability cache.\")\n",
    "    ready_in_memory = ready_probs_on_disk = ready_assets_on_disk = False\n",
    "\n",
    "# ===================== Data Branch: Train or Load from Cache =====================\n",
    "if ready_in_memory:\n",
    "    print(\"[INFO] Reusing probabilities and labels from current session (no retrain)\")\n",
    "    p_val_avg = globals()[\"p_val_avg\"]\n",
    "    p_test_avg = globals()[\"p_test_avg\"]\n",
    "    y_val = globals()[\"y_val\"]\n",
    "    y_test = globals()[\"y_test\"]\n",
    "\n",
    "elif ready_probs_on_disk and ready_assets_on_disk:\n",
    "    print(\"[INFO] Loading probabilities, labels and assets from disk cache (no retrain)\")\n",
    "    p_val_avg  = np.load(VAL_PROBS_NPY)\n",
    "    p_test_avg = np.load(TEST_PROBS_NPY)\n",
    "    y_val      = np.load(VAL_Y_NPY)\n",
    "    y_test     = np.load(TEST_Y_NPY)\n",
    "\n",
    "else:\n",
    "    print(\"[INFO] No valid cache found → performing training to generate probabilities and assets (reusable next time)\")\n",
    "\n",
    "    # Load data & feature names\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    protein_names    = df.columns[PROTEIN_SLICE].tolist()\n",
    "    covariates_names = df.columns[COVARIATE_SLICE].tolist()\n",
    "    all_feature_names = protein_names + covariates_names\n",
    "    num_proteins = len(protein_names)\n",
    "\n",
    "    # Index-level split, save indices for reproducibility\n",
    "    idx_all = np.arange(len(df))\n",
    "    y_all = df.iloc[:, 1].values.astype(np.int32)\n",
    "\n",
    "    idx_train, idx_test = train_test_split(\n",
    "        idx_all, test_size=0.2, random_state=RANDOM_STATE, stratify=y_all\n",
    "    )\n",
    "    y_train_tmp = y_all[idx_train]\n",
    "    idx_subtrain, idx_val = train_test_split(\n",
    "        idx_train, test_size=0.3, random_state=RANDOM_STATE, stratify=y_train_tmp\n",
    "    )\n",
    "\n",
    "    # Save split indices\n",
    "    np.save(IDX_TRAIN_NPY, idx_train)\n",
    "    np.save(IDX_VAL_NPY,   idx_val)\n",
    "    np.save(IDX_TEST_NPY,  idx_test)\n",
    "\n",
    "    # Extract matrices\n",
    "    y_train = y_all[idx_train]\n",
    "    y_val   = y_all[idx_val]\n",
    "    y_test  = y_all[idx_test]\n",
    "    Xp_train = df.iloc[idx_train, PROTEIN_SLICE].values.astype(np.float32)\n",
    "    Xc_train = df.iloc[idx_train, COVARIATE_SLICE].values.astype(np.float32)\n",
    "    Xp_val   = df.iloc[idx_val,   PROTEIN_SLICE].values.astype(np.float32)\n",
    "    Xc_val   = df.iloc[idx_val,   COVARIATE_SLICE].values.astype(np.float32)\n",
    "    Xp_test  = df.iloc[idx_test,  PROTEIN_SLICE].values.astype(np.float32)\n",
    "    Xc_test  = df.iloc[idx_test,  COVARIATE_SLICE].values.astype(np.float32)\n",
    "\n",
    "    # Preprocessors (fit on train), save\n",
    "    imp_p = SimpleImputer(strategy='mean')\n",
    "    imp_c = SimpleImputer(strategy='mean')\n",
    "    Xp_tr = imp_p.fit_transform(Xp_train)\n",
    "    Xp_val = imp_p.transform(Xp_val)\n",
    "    Xp_te = imp_p.transform(Xp_test)\n",
    "    Xc_tr = imp_c.fit_transform(Xc_train)\n",
    "    Xc_val = imp_c.transform(Xc_val)\n",
    "    Xc_te = imp_c.transform(Xc_test)\n",
    "\n",
    "    sc_p = StandardScaler()\n",
    "    sc_c = StandardScaler()\n",
    "    Xp_tr = sc_p.fit_transform(Xp_tr)\n",
    "    Xp_val = sc_p.transform(Xp_val)\n",
    "    Xp_te = sc_p.transform(Xp_te)\n",
    "    Xc_tr = sc_c.fit_transform(Xc_tr)\n",
    "    Xc_val = sc_c.transform(Xc_val)\n",
    "    Xc_te = sc_c.transform(Xc_te)\n",
    "\n",
    "    # Concatenate\n",
    "    X_train = np.hstack([Xp_tr, Xc_tr]).astype(np.float32)\n",
    "    X_val_m = np.hstack([Xp_val, Xc_val]).astype(np.float32)\n",
    "    X_test  = np.hstack([Xp_te, Xc_te]).astype(np.float32)\n",
    "\n",
    "    # Save preprocessors\n",
    "    joblib.dump(imp_p, IMP_P_PKL)\n",
    "    joblib.dump(imp_c, IMP_C_PKL)\n",
    "    joblib.dump(sc_p,  SC_P_PKL)\n",
    "    joblib.dump(sc_c,  SC_C_PKL)\n",
    "\n",
    "    # Save feature names\n",
    "    json.dump(\n",
    "        {\"protein\": protein_names, \"covariates\": covariates_names},\n",
    "        open(FEATURE_NAMES_JSON, \"w\", encoding=\"utf-8\"),\n",
    "        ensure_ascii=False,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "    # Prior (boost middle classes)\n",
    "    prior_counts = np.array([(y_train == k).sum() for k in range(NUM_CLASSES)], dtype=np.float32)\n",
    "    train_prior = prior_counts / prior_counts.sum()\n",
    "    mid_prior = np.array([0.08, 0.22, 0.40, 0.22, 0.08], dtype=np.float32)\n",
    "    mid_prior /= mid_prior.sum()\n",
    "    mix_prior = 0.5 * train_prior + 0.5 * mid_prior\n",
    "\n",
    "    T_train = gaussian_label_distribution(y_train, NUM_CLASSES, sigma=SIGMA_LDL)\n",
    "    T_val   = gaussian_label_distribution(y_val,   NUM_CLASSES, sigma=SIGMA_LDL)\n",
    "    T_test  = gaussian_label_distribution(y_test,  NUM_CLASSES, sigma=SIGMA_LDL)\n",
    "\n",
    "    # Grid search (simplified — no mixup during GS for stability)\n",
    "    layer_configs = [[512,256,128], [256,128]]\n",
    "    dropout_rates = [0.2]\n",
    "    l2_lambdas    = [1e-3]\n",
    "    learning_rates= [1e-3, 5e-4, 3e-4]\n",
    "    callbacks_gs = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4,\n",
    "                                             min_lr=1e-6, verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,\n",
    "                                         restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "    best_params = None\n",
    "    best_obj = -1.0\n",
    "    best_sel = None\n",
    "    protein_indices_arr = np.arange(len(protein_names))\n",
    "\n",
    "    for layer_sizes in layer_configs:\n",
    "        for dr in dropout_rates:\n",
    "            for l2l in l2_lambdas:\n",
    "                for lr in learning_rates:\n",
    "                    print(f\"[GS] layers={layer_sizes}, dropout={dr}, l2={l2l}, lr={lr}\")\n",
    "                    tf.keras.backend.clear_session()\n",
    "                    model = OrdinalLDL(\n",
    "                        input_dim=X_train.shape[1],\n",
    "                        num_classes=NUM_CLASSES,\n",
    "                        layer_sizes=layer_sizes,\n",
    "                        dropout_rate=dr,\n",
    "                        l2_lambda=l2l,\n",
    "                        protein_indices=protein_indices_arr,\n",
    "                        tau=TAU,\n",
    "                        emd_lambda=1.0,\n",
    "                        entropy_lambda=0.10,\n",
    "                        kl_lambda=1.2,\n",
    "                        train_prior=mix_prior,\n",
    "                        mono_mode=MONO_MODE\n",
    "                    )\n",
    "                    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr, clipvalue=1.0))\n",
    "                    model.fit(\n",
    "                        make_dataset(X_train, y_train, T_train, BATCH_SIZE, training=True, mixup_alpha=0.0),\n",
    "                        epochs=EPOCHS_GS,\n",
    "                        validation_data=make_dataset(X_val_m, y_val, T_val, BATCH_SIZE, training=False),\n",
    "                        callbacks=callbacks_gs,\n",
    "                        verbose=0\n",
    "                    )\n",
    "                    p_val_tmp, ey_val_tmp = predict_probs_and_ey(model, X_val_m)\n",
    "                    sel = search_calibration_ext(y_val, p_val_tmp, weights=OBJ_WEIGHTS)\n",
    "                    if sel['obj'] > best_obj:\n",
    "                        best_obj = sel['obj']\n",
    "                        best_params = {'layers':layer_sizes, 'dropout':dr, 'l2':l2l, 'lr':lr}\n",
    "                        best_sel = sel\n",
    "\n",
    "    print(\"[GS] Best configuration:\", best_params, \"| sel=\", best_sel)\n",
    "\n",
    "    # Save best architecture / hyperparameters (used for model reconstruction & SHAP)\n",
    "    json.dump(\n",
    "        {\"best_params\": best_params, \"mono_mode\": MONO_MODE, \"tau\": TAU, \"num_classes\": NUM_CLASSES},\n",
    "        open(MODEL_PARAMS_JSON, \"w\", encoding=\"utf-8\"),\n",
    "        ensure_ascii=False,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "    # Final training + ensemble (batch-level MixUp)\n",
    "    callbacks_final = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5,\n",
    "                                             min_lr=1e-6, verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12,\n",
    "                                         restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "    models = []\n",
    "    train_ds = make_dataset(X_train, y_train, T_train, BATCH_SIZE, training=True, mixup_alpha=0.3)\n",
    "    val_ds   = make_dataset(X_val_m, y_val,   T_val,   BATCH_SIZE, training=False)\n",
    "\n",
    "    for seed in range(N_ENSEMBLE):\n",
    "        tf.keras.backend.clear_session()\n",
    "        np.random.seed(RANDOM_STATE + seed)\n",
    "        tf.random.set_seed(RANDOM_STATE + seed)\n",
    "        m = OrdinalLDL(\n",
    "            input_dim=X_train.shape[1],\n",
    "            num_classes=NUM_CLASSES,\n",
    "            layer_sizes=best_params['layers'],\n",
    "            dropout_rate=best_params['dropout'],\n",
    "            l2_lambda=best_params['l2'],\n",
    "            protein_indices=protein_indices_arr,\n",
    "            tau=TAU,\n",
    "            emd_lambda=1.0,\n",
    "            entropy_lambda=0.10,\n",
    "            kl_lambda=1.2,\n",
    "            train_prior=mix_prior,\n",
    "            mono_mode=MONO_MODE\n",
    "        )\n",
    "        m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['lr'], clipvalue=1.0))\n",
    "        m.fit(train_ds, epochs=EPOCHS_FIN, validation_data=val_ds,\n",
    "              callbacks=callbacks_final, verbose=2)\n",
    "        models.append(m)\n",
    "\n",
    "    # Save first ensemble member's weights (for SHAP)\n",
    "    models[0].save_weights(ENS0_WEIGHTS_H5)\n",
    "\n",
    "    # Compute & cache ensemble probabilities + labels\n",
    "    def ensemble_probs(models, X):\n",
    "        ps = []\n",
    "        for m in models:\n",
    "            p, _ = predict_probs_and_ey(m, X)\n",
    "            ps.append(p)\n",
    "        return np.mean(ps, axis=0)\n",
    "\n",
    "    p_val_avg  = ensemble_probs(models, X_val_m)\n",
    "    p_test_avg = ensemble_probs(models, X_test)\n",
    "\n",
    "    np.save(VAL_PROBS_NPY, p_val_avg)\n",
    "    np.save(TEST_PROBS_NPY, p_test_avg)\n",
    "    np.save(VAL_Y_NPY, y_val)\n",
    "    np.save(TEST_Y_NPY, y_test)\n",
    "\n",
    "    # Write meta fingerprint\n",
    "    json.dump(meta_now, open(META_JSON, \"w\", encoding=\"utf-8\"),\n",
    "              ensure_ascii=False, indent=2)\n",
    "\n",
    "# ===================== Post-processing Calibration (extreme-class friendly) =====================\n",
    "print(\"\\n[CALIB] Performing extreme-class-friendly post-processing search ...\")\n",
    "best_sel = search_calibration_ext(y_val, p_val_avg, weights=OBJ_WEIGHTS)\n",
    "\n",
    "# Optional: fine-tune only the last cut to boost class-4 recall (with safety constraints)\n",
    "base_acc = base_qwk = base_macro = None\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "if best_sel.get(\"mode\", \"cut\") == \"cut\" and \"cuts\" in best_sel:\n",
    "    classes = np.arange(NUM_CLASSES)\n",
    "    def _eval_on(y_true, p_mat, sel):\n",
    "        y_hat = apply_selection(sel, p_mat)\n",
    "        acc   = accuracy_score(y_true, y_hat)\n",
    "        qwk   = quadratic_weighted_kappa(y_true, y_hat, C=NUM_CLASSES)\n",
    "        macro = f1_score(y_true, y_hat, average='macro', zero_division=0)\n",
    "        rec4  = recall_score(y_true, y_hat, labels=[4], average='macro', zero_division=0)\n",
    "        return acc, qwk, macro, rec4\n",
    "\n",
    "    base_acc, base_qwk, base_macro, base_rec4 = _eval_on(y_val, p_val_avg, best_sel)\n",
    "    cuts0 = list(best_sel[\"cuts\"])\n",
    "    best_cand = None\n",
    "\n",
    "    for delta in np.linspace(-0.35, 0.0, 36):\n",
    "        c2 = cuts0.copy()\n",
    "        c2[-1] = cuts0[-1] + float(delta)\n",
    "        if len(c2) >= 2 and c2[-1] <= c2[-2] + 1e-6:\n",
    "            continue\n",
    "        sel2 = dict(best_sel)\n",
    "        sel2[\"cuts\"] = tuple(c2)\n",
    "        acc, qwk, macro, rec4 = _eval_on(y_val, p_val_avg, sel2)\n",
    "        safe = (acc >= base_acc - 0.005) and (qwk >= base_qwk - 0.010)\n",
    "        if not safe:\n",
    "            continue\n",
    "        if (best_cand is None or\n",
    "            (rec4 > best_cand[\"rec4\"] + 1e-9) or\n",
    "            (abs(rec4 - best_cand[\"rec4\"]) < 1e-9 and\n",
    "             (acc > best_cand[\"acc\"] or\n",
    "              (abs(acc - best_cand[\"acc\"]) < 1e-12 and qwk > best_cand[\"qwk\"]))))):\n",
    "            best_cand = dict(sel=sel2, acc=acc, qwk=qwk, macro=macro, rec4=rec4, delta=delta)\n",
    "\n",
    "    if best_cand is not None:\n",
    "        print(f\"[t4-tune] Applying Δt4={best_cand['delta']:.3f} | \"\n",
    "              f\"Val Acc {base_acc:.4f} → {best_cand['acc']:.4f}, \"\n",
    "              f\"QWK {base_qwk:.4f} → {best_cand['qwk']:.4f}, \"\n",
    "              f\"Rec4 {base_rec4:.4f} → {best_cand['rec4']:.4f}\")\n",
    "        best_sel = best_cand[\"sel\"]\n",
    "\n",
    "# Save final calibration parameters\n",
    "json.dump(best_sel, open(BEST_SEL_JSON, \"w\", encoding=\"utf-8\"),\n",
    "          ensure_ascii=False, indent=2)\n",
    "print(\"[CALIB] Best selection (final):\", best_sel)\n",
    "\n",
    "# ===== Apply to test set & report =====\n",
    "y_pred_cal = apply_selection(best_sel, p_test_avg)\n",
    "\n",
    "print(\"\\n== After calibration (final) ==\")\n",
    "print(classification_report(y_test, y_pred_cal, digits=4, zero_division=0))\n",
    "print(\"MAE (calibrated):\", mean_absolute_error(y_test, y_pred_cal))\n",
    "print(\"QWK (calibrated):\", quadratic_weighted_kappa(y_test, y_pred_cal, C=NUM_CLASSES))\n",
    "\n",
    "# Visualization: row-normalized confusion matrix\n",
    "classes = np.arange(NUM_CLASSES)\n",
    "cm = confusion_matrix(y_test, y_pred_cal, labels=classes)\n",
    "row_sums = cm.sum(axis=1, keepdims=True) + 1e-12\n",
    "cm_norm = cm / row_sums\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "im = plt.imshow(cm_norm, interpolation='nearest', aspect='auto')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.title(\"Confusion Matrix (Row-normalized)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(classes)\n",
    "plt.yticks(classes)\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        val = cm_norm[i, j] * 100\n",
    "        plt.text(j, i, f\"{val:.1f}%\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_confusion_matrix_rownorm_extcal.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "\n",
    "# Adjacent accuracy\n",
    "adj_acc = (np.abs(y_test - y_pred_cal) <= 1).mean()\n",
    "print(f\"Adjacent Accuracy = {adj_acc:.4f}\")\n",
    "\n",
    "# ===================== SHAP: E[y]_rev (requires assets to exist) =====================\n",
    "def ey_rev_from_score(score, alpha, tau=TAU):\n",
    "    logits = (score - alpha[tf.newaxis,:]) / tau\n",
    "    probs_gt = tf.sigmoid(logits)\n",
    "    p0 = 1 - probs_gt[:, :1]\n",
    "    p_mid = probs_gt[:, :-1] - probs_gt[:, 1:] if probs_gt.shape[1] > 1 else tf.zeros((tf.shape(score)[0], 0), score.dtype)\n",
    "    plast = probs_gt[:, -1:]\n",
    "    p = tf.concat([p0, p_mid, plast], axis=1)\n",
    "    p = tf.clip_by_value(p, 1e-7, 1.0)\n",
    "    p = p / tf.reduce_sum(p, axis=1, keepdims=True)\n",
    "    C = tf.shape(p)[1]\n",
    "    classes_rev = tf.cast(tf.range(C-1, -1, -1), p.dtype)\n",
    "    ey_rev = tf.reduce_sum(p * classes_rev, axis=1, keepdims=True)\n",
    "    return ey_rev\n",
    "\n",
    "if assets_exist():\n",
    "    print(\"[SHAP] Loading assets and reconstructing model/data for SHAP computation ...\")\n",
    "\n",
    "    # Load parameters & feature names\n",
    "    params_all = json.load(open(MODEL_PARAMS_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    best_params = params_all[\"best_params\"]\n",
    "    feature_names = json.load(open(FEATURE_NAMES_JSON, \"r\", encoding=\"utf-8\"))\n",
    "    protein_names = feature_names[\"protein\"]\n",
    "    covariates_names = feature_names[\"covariates\"]\n",
    "    num_proteins = len(protein_names)\n",
    "\n",
    "    # Load indices & preprocessors, reconstruct X_test (consistent with training)\n",
    "    idx_test = np.load(IDX_TEST_NPY)\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    Xp_test_raw = df.iloc[idx_test, PROTEIN_SLICE].values.astype(np.float32)\n",
    "    Xc_test_raw = df.iloc[idx_test, COVARIATE_SLICE].values.astype(np.float32)\n",
    "\n",
    "    imp_p = joblib.load(IMP_P_PKL)\n",
    "    imp_c = joblib.load(IMP_C_PKL)\n",
    "    sc_p  = joblib.load(SC_P_PKL)\n",
    "    sc_c  = joblib.load(SC_C_PKL)\n",
    "    Xp_te = sc_p.transform(imp_p.transform(Xp_test_raw))\n",
    "    Xc_te = sc_c.transform(imp_c.transform(Xc_test_raw))\n",
    "    X_test_for_shap = np.hstack([Xp_te, Xc_te]).astype(np.float32)\n",
    "\n",
    "    # Rebuild model (single) and load ens0 weights\n",
    "    tf.keras.backend.clear_session()\n",
    "    m0 = OrdinalLDL(\n",
    "        input_dim=X_test_for_shap.shape[1],\n",
    "        num_classes=NUM_CLASSES,\n",
    "        layer_sizes=best_params[\"layers\"],\n",
    "        dropout_rate=best_params[\"dropout\"],\n",
    "        l2_lambda=best_params[\"l2\"],\n",
    "        protein_indices=np.arange(num_proteins),\n",
    "        tau=params_all.get(\"tau\", TAU),\n",
    "        emd_lambda=1.0,\n",
    "        entropy_lambda=0.10,\n",
    "        kl_lambda=1.2,\n",
    "        train_prior=None,\n",
    "        mono_mode=params_all.get(\"mono_mode\", MONO_MODE)\n",
    "    )\n",
    "    m0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[\"lr\"], clipvalue=1.0))\n",
    "    m0.build((None, X_test_for_shap.shape[1]))\n",
    "    m0.load_weights(ENS0_WEIGHTS_H5)\n",
    "\n",
    "    # Build Keras model that outputs E[y]_rev\n",
    "    inp = tf.keras.Input(shape=(X_test_for_shap.shape[1],), dtype=tf.float32)\n",
    "    score = m0(inp, training=False)\n",
    "    alpha_tf = m0.get_alphas()\n",
    "    ey_rev_out = tf.keras.layers.Lambda(\n",
    "        lambda s: ey_rev_from_score(s, alpha_tf, TAU),\n",
    "        name=\"expected_severity_rev\"\n",
    "    )(score)\n",
    "    EyRev_model = tf.keras.Model(inputs=inp, outputs=ey_rev_out)\n",
    "\n",
    "    # Background & subset\n",
    "    background = shap.kmeans(X_test_for_shap, 100).data\n",
    "    n_samples = min(2000, len(X_test_for_shap))\n",
    "    test_subset = X_test_for_shap[:n_samples].astype(np.float32)\n",
    "\n",
    "    explainer = shap.GradientExplainer(EyRev_model, background)\n",
    "    sv = explainer.shap_values(test_subset)\n",
    "    if isinstance(sv, list):\n",
    "        sv = sv[0]\n",
    "    sv = np.asarray(sv)\n",
    "    if sv.ndim == 3 and sv.shape[-1] == 1:\n",
    "        sv = sv[...,0]\n",
    "    elif sv.ndim != 2:\n",
    "        raise ValueError(f\"Unexpected SHAP shape {sv.shape}\")\n",
    "    print(\"SHAP values shape:\", sv.shape)\n",
    "\n",
    "    # Export importance\n",
    "    sv_prot = sv[:, :num_proteins]\n",
    "    mean_abs = np.mean(np.abs(sv_prot), axis=0).ravel()\n",
    "    pd.DataFrame({\"feature\": protein_names, \"mean_abs_shap_Ey_rev\": mean_abs}) \\\n",
    "      .to_csv(os.path.join(OUT_DIR, \"protein_importance_Ey_rev.csv\"),\n",
    "              index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"Saved: protein_importance_Ey_rev.csv\")\n",
    "\n",
    "    # Top-K dependence plots\n",
    "    TOPK = 10\n",
    "    sorted_idx = np.argsort(-mean_abs)\n",
    "    for rank, j in enumerate(sorted_idx[:TOPK], 1):\n",
    "        plt.figure()\n",
    "        shap.dependence_plot(\n",
    "            ind=j,\n",
    "            shap_values=sv,\n",
    "            features=test_subset,\n",
    "            feature_names=protein_names + covariates_names,\n",
    "            interaction_index=None,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f\"E[y]_rev SHAP Dependence — Top{rank}: {protein_names[j]}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"dep_Eyrev_top{rank}_{protein_names[j]}.pdf\"),\n",
    "                    format=\"pdf\")\n",
    "        plt.close()\n",
    "    print(\"Saved: dep_Eyrev_top*.pdf\")\n",
    "\n",
    "    # Overall beeswarm (proteins only)\n",
    "    plt.figure()\n",
    "    shap.summary_plot(\n",
    "        sv[:, :num_proteins],\n",
    "        test_subset[:, :num_proteins],\n",
    "        feature_names=protein_names,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\"E[y]_rev SHAP Summary (Proteins)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"shap_summary_beeswarm_Ey_rev_proteins.pdf\"),\n",
    "                format=\"pdf\")\n",
    "    plt.close()\n",
    "    print(\"Saved: shap_summary_beeswarm_Ey_rev_proteins.pdf\")\n",
    "\n",
    "else:\n",
    "    print(\"[SHAP] Warning: missing model assets (preprocessor/weights/params/indices/feature names). \"\n",
    "          \"Skipping SHAP this time.\\n\"\n",
    "          \"To run SHAP, set FORCE_TRAIN=True and run once, or delete cache to force retraining.\")\n",
    "\n",
    "print(\"\\n✅ Pipeline completed. Outputs are located in:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c23c6-cb63-40bb-b398-61eb8bbc7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Stage-C: Three-strategy joint enhancement of the tail (class 4), post-processing only ===\n",
    "# Parameters are tuned on validation set and applied to test set\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "# Allowed performance degradation relative to the baseline E[y] cut (best_sel on validation)\n",
    "MAX_ACC_DROP = 0.015   # 1.5%\n",
    "MAX_QWK_DROP = 0.020   # 0.02\n",
    "\n",
    "classes = np.arange(NUM_CLASSES)\n",
    "\n",
    "def eval_metrics(y_true, y_hat):\n",
    "    acc  = accuracy_score(y_true, y_hat)\n",
    "    qwk  = quadratic_weighted_kappa(y_true, y_hat, C=NUM_CLASSES)\n",
    "    macro = f1_score(y_true, y_hat, average='macro', zero_division=0)\n",
    "    rec4 = recall_score(y_true, y_hat, labels=[4], average='macro', zero_division=0)\n",
    "    rec3 = recall_score(y_true, y_hat, labels=[3], average='macro', zero_division=0)\n",
    "    return dict(acc=acc, qwk=qwk, macro=macro, rec4=rec4, rec3=rec3)\n",
    "\n",
    "# Baseline: performance of current best_sel (E[y] cut) on validation set\n",
    "y_hat_base_val = apply_selection(best_sel, p_val_avg)\n",
    "base = eval_metrics(y_val, y_hat_base_val)\n",
    "\n",
    "def apply_selection_cdf(params, p_mat):\n",
    "    \"\"\" Ordered CDF decision: take the largest k where S_k >= t_k; only t1..t4 used, t4 directly on p4 \"\"\"\n",
    "    C = NUM_CLASSES\n",
    "    p_g = softmax_power(p_mat, params['gamma'])\n",
    "    S = np.cumsum(p_g[:, ::-1], axis=1)[:, ::-1]   # S[:,k] = sum_{j>=k} p_j\n",
    "    t = np.array(params['thresh'], dtype=float)     # length C (t0 placeholder, t4 acts on S4=p4)\n",
    "    y_hat = np.zeros(p_g.shape[0], dtype=int)\n",
    "    for k in range(1, C):\n",
    "        y_hat = np.where(S[:, k] >= t[k], np.maximum(y_hat, k), y_hat)\n",
    "    return y_hat\n",
    "\n",
    "def reweight_probs(p, w_vec):\n",
    "    \"\"\" Multiply by class weights and renormalize; w_vec length = C \"\"\"\n",
    "    q = p * w_vec[None, :]\n",
    "    q = q / (q.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    return q\n",
    "\n",
    "def choose_better(current_best, candidate, why):\n",
    "    \"\"\" Maximize Rec4 first; ties broken by QWK > ACC > Macro; record strategy origin \"\"\"\n",
    "    if current_best is None:\n",
    "        cand = dict(candidate)\n",
    "        cand['_why'] = why\n",
    "        return cand\n",
    "    a, b = current_best, candidate\n",
    "    if (b['rec4'] > a['rec4'] + 1e-12 or\n",
    "        (abs(b['rec4'] - a['rec4']) <= 1e-12 and (\n",
    "            b['qwk'] > a['qwk'] + 1e-12 or\n",
    "            (abs(b['qwk'] - a['qwk']) <= 1e-12 and (\n",
    "                b['acc'] > a['acc'] + 1e-12 or\n",
    "                (abs(b['acc'] - a['acc']) <= 1e-12 and b['macro'] > a['macro'] + 1e-12)\n",
    "            ))\n",
    "        ))):\n",
    "        cand = dict(candidate)\n",
    "        cand['_why'] = why\n",
    "        return cand\n",
    "    return current_best\n",
    "\n",
    "best_pick = None\n",
    "\n",
    "# ---------- Strategy 1: CDF joint thresholds (t3 & t4) + gamma sharpening ----------\n",
    "gamma_base = float(best_sel.get('gamma', 1.0))\n",
    "gamma_mult_list = [1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "t3_grid = np.linspace(0.45, 0.65, 9)    # tuning t3 reduces 4→3 misclassifications\n",
    "t4_grid = np.linspace(0.25, 0.60, 15)   # tuning t4 directly boosts Rec4\n",
    "\n",
    "for gmul in gamma_mult_list:\n",
    "    gamma_try = gamma_base * gmul\n",
    "    for t3 in t3_grid:\n",
    "        for t4 in t4_grid:\n",
    "            t = [1.0, 0.50, 0.50, float(t3), float(t4)]  # t1,t2 commonly set to 0.5\n",
    "            params = {\"mode\": \"cdf\", \"gamma\": gamma_try, \"thresh\": t}\n",
    "            y_hat_val = apply_selection_cdf(params, p_val_avg)\n",
    "            m = eval_metrics(y_val, y_hat_val)\n",
    "            # Safety constraints\n",
    "            if (m['acc'] >= base['acc'] - MAX_ACC_DROP) and (m['qwk'] >= base['qwk'] - MAX_QWK_DROP):\n",
    "                best_pick = choose_better(best_pick, dict(m, params=params), \"CDF(t3,t4)+gamma\")\n",
    "\n",
    "# ---------- Strategy 2: Reweight p4 (can slightly suppress p3), then apply E[y] cut ----------\n",
    "a0, b0 = float(best_sel.get('a', 1.0)), float(best_sel.get('b', 0.0))\n",
    "cuts0 = best_sel.get('cuts', None)\n",
    "for gmul in [1.0, 1.1, 1.2, 1.3, 1.4]:\n",
    "    gamma_try = gamma_base * gmul\n",
    "    p_g_val = softmax_power(p_val_avg, gamma_try)\n",
    "    for w4 in [1.0, 1.2, 1.4, 1.6, 1.8]:\n",
    "        for w3 in [1.0, 0.95, 0.90, 0.85]:\n",
    "            w = np.ones(NUM_CLASSES, dtype=float)\n",
    "            w[4] = w4\n",
    "            w[3] = w3\n",
    "            p_rw = reweight_probs(p_g_val, w)\n",
    "            ey = (p_rw * classes[None, :]).sum(axis=1)\n",
    "            y_hat_val = digitize_with_cuts(a0 * ey + b0, cuts0)\n",
    "            m = eval_metrics(y_val, y_hat_val)\n",
    "            if (m['acc'] >= base['acc'] - MAX_ACC_DROP) and (m['qwk'] >= base['qwk'] - MAX_QWK_DROP):\n",
    "                best_pick = choose_better(best_pick,\n",
    "                                          dict(m, params={\"mode\": \"ey+reweight\", \"gamma\": gamma_try, \"w\": w.tolist()}),\n",
    "                                          \"Reweight(p4↑,p3↓)+E[y]\")\n",
    "\n",
    "# ---------- Strategy 3: Two-stage hierarchy: first 4-vs-rest (S4=p4 threshold), rest use original E[y] ----------\n",
    "for gmul in [1.0, 1.1, 1.2, 1.3]:\n",
    "    gamma_try = gamma_base * gmul\n",
    "    p_g_val = softmax_power(p_val_avg, gamma_try)\n",
    "    p4 = p_g_val[:, 4]\n",
    "    for th4 in np.linspace(0.25, 0.65, 17):\n",
    "        mask4 = (p4 >= th4)\n",
    "        # First apply original E[y] decision, then override mask4 to class 4\n",
    "        y_hat_val = apply_selection(best_sel, p_val_avg).copy()  # keep original gamma-based E[y] cut as base\n",
    "        y_hat_val[mask4] = 4\n",
    "        m = eval_metrics(y_val, y_hat_val)\n",
    "        if (m['acc'] >= base['acc'] - MAX_ACC_DROP) and (m['qwk'] >= base['qwk'] - MAX_QWK_DROP):\n",
    "            best_pick = choose_better(best_pick,\n",
    "                                      dict(m, params={\"mode\": \"hier4\", \"gamma\": gamma_try, \"th4\": float(th4)}),\n",
    "                                      \"Hierarchical 4-vs-rest\")\n",
    "\n",
    "# ---------- Select best and apply to test set ----------\n",
    "if best_pick is None:\n",
    "    print(\"[Stage-C] No method found that further improves Rec4 within safety constraints; keeping original E[y] cut.\")\n",
    "    y_pred_cal = apply_selection(best_sel, p_test_avg)\n",
    "else:\n",
    "    print(f\"[Stage-C] Selected strategy: {best_pick['_why']} | \"\n",
    "          f\"Val: Acc {base['acc']:.4f} → {best_pick['acc']:.4f}, \"\n",
    "          f\"QWK {base['qwk']:.4f} → {best_pick['qwk']:.4f}, \"\n",
    "          f\"Rec4 {base['rec4']:.4f} → {best_pick['rec4']:.4f}\")\n",
    "    mode = best_pick['params']['mode']\n",
    "\n",
    "    if mode == \"cdf\":\n",
    "        y_pred_cal = apply_selection_cdf(best_pick['params'], p_test_avg)\n",
    "        best_sel = dict(best_sel)\n",
    "        best_sel.update(best_pick['params'])\n",
    "    elif mode == \"ey+reweight\":\n",
    "        p_g_test = softmax_power(p_test_avg, best_pick['params']['gamma'])\n",
    "        p_rw_test = reweight_probs(p_g_test, np.array(best_pick['params']['w'], dtype=float))\n",
    "        ey = (p_rw_test * classes[None, :]).sum(axis=1)\n",
    "        y_pred_cal = digitize_with_cuts(a0 * ey + b0, cuts0)\n",
    "        best_sel = dict(best_sel)\n",
    "        best_sel.update(best_pick['params'])\n",
    "    elif mode == \"hier4\":\n",
    "        p_g_test = softmax_power(p_test_avg, best_pick['params']['gamma'])\n",
    "        y_pred_cal = apply_selection(best_sel, p_test_avg).copy()\n",
    "        y_pred_cal[p_g_test[:, 4] >= best_pick['params']['th4']] = 4\n",
    "        best_sel = dict(best_sel)\n",
    "        best_sel.update(best_pick['params'])\n",
    "    else:\n",
    "        # Fallback (should not reach here)\n",
    "        y_pred_cal = apply_selection(best_sel, p_test_avg)\n",
    "\n",
    "# —— Print 4→3 confusion fraction on test set for verification —— #\n",
    "cm_test = confusion_matrix(y_test, y_pred_cal, labels=np.arange(NUM_CLASSES))\n",
    "if cm_test[4].sum() > 0:\n",
    "    frac_4_to_3 = cm_test[4, 3] / cm_test[4].sum()\n",
    "    print(f\"[Test] Class-4 accuracy={cm_test[4,4]/cm_test[4].sum():.3f}, \"\n",
    "          f\"4→3 misclassification fraction={frac_4_to_3:.3f} (row-normalized)\")\n",
    "else:\n",
    "    print(\"[Test] No true class-4 samples in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09130126-2399-4e59-80a0-d3ddcc14e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —— Finalize and save this scheme (save best_sel + test set predictions) ——\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# (Optional) If you saved a baseline before Stage-C: best_sel_base = dict(best_sel_before_stageC)\n",
    "# Here we save it together for future comparison (if it exists)\n",
    "artifacts = {\n",
    "    \"best_sel_final\": best_sel,   # Already includes mode, gamma, th4, etc. if Hier4 was selected\n",
    "}\n",
    "\n",
    "# Save final configuration as JSON\n",
    "with open(os.path.join(OUT_DIR, \"best_selection_final.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(artifacts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Save final test predictions\n",
    "np.save(os.path.join(OUT_DIR, \"y_pred_test_final.npy\"), y_pred_cal)\n",
    "\n",
    "# Print and save test set report\n",
    "rep_new = classification_report(y_test, y_pred_cal, digits=4, zero_division=0)\n",
    "print(\"\\n[TEST REPORT — Hier4 (final)]\\n\", rep_new)\n",
    "\n",
    "with open(os.path.join(OUT_DIR, \"test_report_hier4_final.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(rep_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a105991-07f8-4a3c-abcf-fc0ac32eceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Fixed Version: Load Final Scheme + Reproduce Predictions + Generate All Plots =====\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# >>> 1) Align paths to your training/saving directory <<< (very important)\n",
    "OUT_DIR = \"./results/Gradually_Increasing\"\n",
    "\n",
    "# Cache and final selection files (note the filenames)\n",
    "VAL_PROBS_NPY  = os.path.join(OUT_DIR, \"cache_val_probs.npy\")\n",
    "TEST_PROBS_NPY = os.path.join(OUT_DIR, \"cache_test_probs.npy\")\n",
    "VAL_Y_NPY      = os.path.join(OUT_DIR, \"cache_val_y.npy\")\n",
    "TEST_Y_NPY     = os.path.join(OUT_DIR, \"cache_test_y.npy\")\n",
    "BEST_SEL_FINAL = os.path.join(OUT_DIR, \"best_selection_final.json\")  # Use the final file\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def softmax_power(p, gamma):\n",
    "    p = np.clip(p, 1e-8, 1.0)\n",
    "    z = p ** gamma\n",
    "    return z / (z.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def digitize_with_cuts(ey, cuts):\n",
    "    bins = [-np.inf] + list(cuts) + [np.inf]\n",
    "    return np.digitize(ey, bins) - 1\n",
    "\n",
    "def ey_from_probs(p, gamma, a, b):\n",
    "    classes = np.arange(p.shape[1])\n",
    "    p_g = softmax_power(p, gamma)\n",
    "    ey = (p_g * classes[None, :]).sum(axis=1)\n",
    "    return a * ey + b, p_g\n",
    "\n",
    "def apply_selection(best_sel, p_val, p_test, y_val=None):\n",
    "    \"\"\"\n",
    "    Supports 3 modes:\n",
    "    - 'cut'  : Use ey + cutpoints\n",
    "    - 'iso'  : Fit isotonic regression on ey (requires y_val/p_val)\n",
    "    - 'hier4': First apply th4 threshold for 4-vs-rest, others keep cut (or iso) decision\n",
    "    Returns: y_pred_test, p_curve_test (for ROC), ey_test\n",
    "    \"\"\"\n",
    "    mode = best_sel.get('mode', 'cut').lower()\n",
    "    gamma = float(best_sel.get('gamma', 1.0))\n",
    "    a = float(best_sel.get('a', 1.0))\n",
    "    b = float(best_sel.get('b', 0.0))\n",
    "\n",
    "    # Compute ey and temperature-scaled probabilities first\n",
    "    ey_val,  p_val_g  = ey_from_probs(p_val,  gamma, a, b)\n",
    "    ey_test, p_test_g = ey_from_probs(p_test, gamma, a, b)\n",
    "\n",
    "    if mode == 'iso':\n",
    "        if y_val is None:\n",
    "            raise ValueError(\"mode='iso' requires y_val to fit isotonic regression on validation set.\")\n",
    "        iso = IsotonicRegression(y_min=0.0, y_max=float(p_test.shape[1]-1),\n",
    "                                 increasing=True, out_of_bounds=\"clip\")\n",
    "        iso.fit(ey_val, y_val.astype(float))\n",
    "        y_pred_test = np.rint(iso.predict(ey_test)).astype(int).clip(0, p_test.shape[1]-1)\n",
    "\n",
    "    elif mode == 'cut':\n",
    "        cuts = best_sel['cuts']\n",
    "        y_pred_test = digitize_with_cuts(ey_test, cuts)\n",
    "\n",
    "    elif mode == 'hier4':\n",
    "        # Base: first apply cut (or iso base) for non-class-4 predictions\n",
    "        if 'cuts' in best_sel:\n",
    "            y_pred_test = digitize_with_cuts(ey_test, best_sel['cuts'])\n",
    "        elif best_sel.get('iso_base', False):\n",
    "            # Rare branch: if you saved an iso baseline, recover it here (default: not present)\n",
    "            if y_val is None:\n",
    "                raise ValueError(\"hier4 + iso_base requires y_val to fit isotonic regression.\")\n",
    "            iso = IsotonicRegression(y_min=0.0, y_max=float(p_test.shape[1]-1),\n",
    "                                     increasing=True, out_of_bounds=\"clip\")\n",
    "            iso.fit(ey_val, y_val.astype(float))\n",
    "            y_pred_test = np.rint(iso.predict(ey_test)).astype(int).clip(0, p_test.shape[1]-1)\n",
    "        else:\n",
    "            # Fallback to cut (most common case)\n",
    "            cuts = best_sel['cuts']\n",
    "            y_pred_test = digitize_with_cuts(ey_test, cuts)\n",
    "\n",
    "        # Top-level threshold: Y≥4 vs rest, using s4 = P(Y=4)\n",
    "        th4 = float(best_sel['th4']) if 'th4' in best_sel else 0.5\n",
    "        s4 = p_test_g[:, -1]             # probability of class 4\n",
    "        pick4 = (s4 >= th4)\n",
    "        y_pred_test[pick4] = p_test.shape[1]-1  # set to 4\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mode: {mode}\")\n",
    "\n",
    "    return y_pred_test, p_test_g, ey_test\n",
    "\n",
    "# --- Load cache and final selection ---\n",
    "assert os.path.exists(TEST_PROBS_NPY), f\"File not found: {TEST_PROBS_NPY}\"\n",
    "assert os.path.exists(BEST_SEL_FINAL), f\"File not found: {BEST_SEL_FINAL} (please run 'Finalize and save scheme' first)\"\n",
    "p_val_avg  = np.load(VAL_PROBS_NPY)\n",
    "p_test_avg = np.load(TEST_PROBS_NPY)\n",
    "y_val      = np.load(VAL_Y_NPY)\n",
    "y_test     = np.load(TEST_Y_NPY)\n",
    "\n",
    "with open(BEST_SEL_FINAL, \"r\", encoding=\"utf-8\") as f:\n",
    "    js = json.load(f)\n",
    "# Handle both save formats: {\"best_sel_final\": {...}} or direct {...}\n",
    "best_sel = js.get(\"best_sel_final\", js)\n",
    "\n",
    "NUM_CLASSES = p_test_avg.shape[1]\n",
    "\n",
    "print(\"[INFO] OUT_DIR =\", OUT_DIR)\n",
    "print(\"[INFO] best_sel.mode =\", best_sel.get(\"mode\"), \"| keys:\", list(best_sel.keys()))\n",
    "\n",
    "# Generate final predictions (supports hier4)\n",
    "y_pred_cal, p_curve, ey_curve = apply_selection(best_sel, p_val_avg, p_test_avg, y_val=y_val)\n",
    "\n",
    "# ====== Quick sanity check: row-normalized class 4 ======\n",
    "cm = confusion_matrix(y_test, y_pred_cal, labels=np.arange(NUM_CLASSES))\n",
    "row = cm[-1] / max(cm[-1].sum(), 1)  # last row = true class 4\n",
    "print(f\"[CHECK] Class-4 row-normalized: {np.round(row, 3)}  (cols=0..4)  | Accuracy = {row[-1]:.3f}\")\n",
    "\n",
    "# ====== Generate all plots (consistent with your previous scripts) ======\n",
    "classes = np.arange(NUM_CLASSES)\n",
    "\n",
    "# 1) Confusion Matrix (row-normalized)\n",
    "row_sums = cm.sum(axis=1, keepdims=True) + 1e-12\n",
    "cm_norm = cm / row_sums\n",
    "plt.figure(figsize=(6,5))\n",
    "im = plt.imshow(cm_norm, interpolation='nearest', aspect='auto')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "tag = f\"Mode={best_sel.get('mode','?')}, γ={best_sel.get('gamma',1.0):.2f}\"\n",
    "if best_sel.get('mode','').lower() == 'hier4':\n",
    "    tag += f\", th4={best_sel.get('th4','-')}\"\n",
    "plt.title(f\"Confusion Matrix (Row-normalized)\\n{tag}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(classes)\n",
    "plt.yticks(classes)\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        val = cm_norm[i, j] * 100\n",
    "        plt.text(j, i, f\"{val:.1f}%\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_confusion_matrix_rownorm_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "\n",
    "# 2) One-vs-Rest ROC\n",
    "plt.figure(figsize=(6,5))\n",
    "macro_auc = []\n",
    "for k in classes:\n",
    "    y_true_k = (y_test == k).astype(int)\n",
    "    fpr, tpr, _ = roc_curve(y_true_k, p_curve[:, k])\n",
    "    auc_k = auc(fpr, tpr)\n",
    "    macro_auc.append(auc_k)\n",
    "    plt.plot(fpr, tpr, label=f\"class {k} (AUC={auc_k:.3f})\")\n",
    "plt.plot([0,1], [0,1], '--')\n",
    "plt.title(f\"OVR ROC — {tag}\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_roc_ovr_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "print(f\"OVR macro AUC: {np.mean(macro_auc):.3f}\")\n",
    "\n",
    "# 3) Ordinal ROC (cumulative Y≥k)\n",
    "plt.figure(figsize=(6,5))\n",
    "auc_ord = []\n",
    "for k in range(1, NUM_CLASSES):\n",
    "    y_true_bin = (y_test >= k).astype(int)\n",
    "    s_k = p_curve[:, k:].sum(axis=1)\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin, s_k)\n",
    "    auc_k = auc(fpr, tpr)\n",
    "    auc_ord.append(auc_k)\n",
    "    plt.plot(fpr, tpr, label=f\"Y≥{k} (AUC={auc_k:.3f})\")\n",
    "plt.plot([0,1], [0,1], '--')\n",
    "plt.title(f\"Ordinal ROC (cumulative) — {tag}\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_roc_ordinal_cumulative_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "print(f\"Ordinal ROC mean AUC: {np.mean(auc_ord):.3f}\")\n",
    "\n",
    "# 4) One-vs-Rest Precision-Recall\n",
    "plt.figure(figsize=(6,5))\n",
    "auprc = []\n",
    "for k in classes:\n",
    "    y_true_k = (y_test == k).astype(int)\n",
    "    prec, rec, _ = precision_recall_curve(y_true_k, p_curve[:, k])\n",
    "    ap = average_precision_score(y_true_k, p_curve[:, k])\n",
    "    auprc.append(ap)\n",
    "    plt.plot(rec, prec, label=f\"class {k} (AP={ap:.3f})\")\n",
    "plt.title(f\"OVR Precision-Recall — {tag}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_pr_ovr_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "print(f\"OVR mean AUPRC: {np.mean(auprc):.3f}\")\n",
    "\n",
    "# 5) E[y] Calibration (binned means)\n",
    "ey_plot = (p_curve * classes[None, :]).sum(axis=1)  # Here using γ-scaled but un-affine E[y]; use ey_curve if you want a,b applied\n",
    "q = np.quantile(ey_plot, np.linspace(0, 1, 11))\n",
    "idx = np.digitize(ey_plot, q[1:-1], right=True)\n",
    "bin_pred, bin_true, bin_n = [], [], []\n",
    "for b in range(len(q)-1):\n",
    "    m = (idx == b)\n",
    "    if m.sum() >= 30:\n",
    "        bin_pred.append(ey_plot[m].mean())\n",
    "        bin_true.append(y_test[m].mean())\n",
    "        bin_n.append(m.sum())\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot([0, NUM_CLASSES-1], [0, NUM_CLASSES-1], linestyle=\"--\")\n",
    "plt.scatter(bin_pred, bin_true, s=np.clip(np.array(bin_n)/2, 10, 200))\n",
    "for bp, bt, n in zip(bin_pred, bin_true, bin_n):\n",
    "    plt.text(bp, bt, str(n), fontsize=8, ha='left', va='bottom')\n",
    "plt.title(f\"E[y] Calibration (bin means) — {tag}\")\n",
    "plt.xlabel(\"Predicted E[y]\")\n",
    "plt.ylabel(\"Observed mean(y)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_calibration_Ey_bins_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "\n",
    "# 6) Adjacent Accuracy by True Class\n",
    "adj_ok = (np.abs(y_pred_cal - y_test) <= 1).astype(float)\n",
    "vals = []\n",
    "for k in classes:\n",
    "    m = (y_test == k)\n",
    "    vals.append(adj_ok[m].mean() if m.any() else np.nan)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(classes, vals)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(f\"Adjacent Accuracy by True Class — {tag}\")\n",
    "plt.xlabel(\"True class\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_adjacent_accuracy_by_class_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "\n",
    "# 7) Error Distribution\n",
    "err = y_pred_cal - y_test\n",
    "plt.figure(figsize=(6,4))\n",
    "bins = np.arange(-(NUM_CLASSES-1)-0.5, (NUM_CLASSES-1)+1.5, 1.0)\n",
    "plt.hist(err, bins=bins, density=True)\n",
    "plt.xticks(range(-(NUM_CLASSES-1), (NUM_CLASSES-1)+1))\n",
    "plt.title(f\"Error distribution (ŷ−y) — {tag}\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_error_hist_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "\n",
    "# 8) QWK Cost Heatmap\n",
    "W = np.zeros((NUM_CLASSES, NUM_CLASSES))\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        W[i, j] = ((i - j) / (NUM_CLASSES - 1)) ** 2\n",
    "cost = W * (cm / (cm.sum() + 1e-12))\n",
    "plt.figure(figsize=(6,5))\n",
    "im = plt.imshow(cost, interpolation='nearest', aspect='auto')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.title(f\"QWK Cost Map — {tag}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(classes)\n",
    "plt.yticks(classes)\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        plt.text(j, i, f\"{cost[i,j]*100:.2f}%\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"viz_qwk_cost_map_FINAL.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✅ All new plots have been saved to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dda904-ad16-44cd-8756-f5ea12ac4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "ROC Comparison (Standalone Script)\n",
    "- Loads probability cache from your deep ordinal model + calibration parameters\n",
    "  (supports best_selection_final.json / best_selection.json)\n",
    "- Reconstructs the same train/test split used in training\n",
    "- Trains baseline models: RandomForest, XGBoost, Ordered Logit\n",
    "- Plots Ordinal ROC curves (cumulative Y≥k) and overlays \"DeepOrdinal(γ+Hier4 aware)\" curve\n",
    "- Outputs: compare_ordinal_roc_with_hier4.pdf, compare_ordinal_auc_bar_with_hier4.pdf\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# ========= 1) Paths & Data Configuration (must match training/saving setup) =========\n",
    "DATA_PATH = \"./data/extracted_Gradually_Increasing.csv\"\n",
    "OUT_DIR   = \"./results/Gradually_Increasing\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "VAL_PROBS_NPY  = os.path.join(OUT_DIR, \"cache_val_probs.npy\")\n",
    "TEST_PROBS_NPY = os.path.join(OUT_DIR, \"cache_test_probs.npy\")\n",
    "VAL_Y_NPY      = os.path.join(OUT_DIR, \"cache_val_y.npy\")\n",
    "TEST_Y_NPY     = os.path.join(OUT_DIR, \"cache_test_y.npy\")\n",
    "BEST_SEL_FINAL = os.path.join(OUT_DIR, \"best_selection_final.json\")\n",
    "BEST_SEL_JSON  = os.path.join(OUT_DIR, \"best_selection.json\")\n",
    "\n",
    "# Column slices used during training (FD example)\n",
    "PROTEIN_SLICE   = slice(9, 76)\n",
    "COVARIATE_SLICE = slice(2, 9)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "NUM_CLASSES  = 5\n",
    "\n",
    "# ========= 2) Helper Functions =========\n",
    "def softmax_power(p, gamma):\n",
    "    p = np.clip(p, 1e-8, 1.0)\n",
    "    z = p ** float(gamma)\n",
    "    return z / (z.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def load_deep_caches():\n",
    "    assert os.path.exists(TEST_PROBS_NPY), f\"Test probabilities not found: {TEST_PROBS_NPY}\"\n",
    "    p_test_avg = np.load(TEST_PROBS_NPY)\n",
    "    p_val_avg  = np.load(VAL_PROBS_NPY)  if os.path.exists(VAL_PROBS_NPY)  else None\n",
    "    y_test     = np.load(TEST_Y_NPY)     if os.path.exists(TEST_Y_NPY)     else None\n",
    "    y_val      = np.load(VAL_Y_NPY)      if os.path.exists(VAL_Y_NPY)      else None\n",
    "\n",
    "    # Prefer final scheme; fallback to best_selection.json if missing\n",
    "    if os.path.exists(BEST_SEL_FINAL):\n",
    "        with open(BEST_SEL_FINAL, \"r\", encoding=\"utf-8\") as f:\n",
    "            obj = json.load(f)\n",
    "        best_sel = obj.get(\"best_sel_final\", obj)\n",
    "    elif os.path.exists(BEST_SEL_JSON):\n",
    "        with open(BEST_SEL_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            best_sel = json.load(f)\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Neither best_selection_final.json nor best_selection.json found.\")\n",
    "\n",
    "    return p_val_avg, p_test_avg, y_val, y_test, best_sel\n",
    "\n",
    "def load_split_Xy():\n",
    "    \"\"\"Reconstruct the exact same train/test split used during model training.\"\"\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    Xp = df.iloc[:, PROTEIN_SLICE].values.astype(np.float32)\n",
    "    Xc = df.iloc[:, COVARIATE_SLICE].values.astype(np.float32)\n",
    "    y  = df.iloc[:, 1].values.astype(np.int32)\n",
    "\n",
    "    Xp_tr, Xp_te, Xc_tr, Xc_te, y_tr, y_te = train_test_split(\n",
    "        Xp, Xc, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    imp_p = SimpleImputer(strategy='mean')\n",
    "    imp_c = SimpleImputer(strategy='mean')\n",
    "    Xp_tr = imp_p.fit_transform(Xp_tr)\n",
    "    Xp_te = imp_p.transform(Xp_te)\n",
    "    Xc_tr = imp_c.fit_transform(Xc_tr)\n",
    "    Xc_te = imp_c.transform(Xc_te)\n",
    "\n",
    "    sc_p = StandardScaler()\n",
    "    sc_c = StandardScaler()\n",
    "    Xp_tr = sc_p.fit_transform(Xp_tr)\n",
    "    Xp_te = sc_p.transform(Xp_te)\n",
    "    Xc_tr = sc_c.fit_transform(Xc_tr)\n",
    "    Xc_te = sc_c.transform(Xc_te)\n",
    "\n",
    "    X_train = np.hstack([Xp_tr, Xc_tr]).astype(np.float32)\n",
    "    X_test  = np.hstack([Xp_te, Xc_te]).astype(np.float32)\n",
    "    return X_train, X_test, y_tr, y_te\n",
    "\n",
    "def ordinal_auc_list(y_true, scores_list):\n",
    "    \"\"\"Given list of scores for each threshold k (length = C-1), return AUCs and macro average.\"\"\"\n",
    "    aucs = []\n",
    "    for s_k in scores_list:\n",
    "        y_bin = (y_true >= (len(aucs) + 1)).astype(int)  # corresponds to Y ≥ k\n",
    "        if len(np.unique(y_bin)) < 2:\n",
    "            aucs.append(np.nan)\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_bin, s_k)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "    return aucs, np.nanmean(aucs)\n",
    "\n",
    "# ========= 3) Load Deep Model Cache =========\n",
    "p_val_avg, p_test_avg, y_val_cache, y_test_cache, best_sel = load_deep_caches()\n",
    "assert p_test_avg.shape[1] == NUM_CLASSES, \"NUM_CLASSES inconsistent with probability columns\"\n",
    "n_test = p_test_avg.shape[0]\n",
    "\n",
    "# ========= 4) Reconstruct X/y split for traditional models =========\n",
    "X_train, X_test, y_train, y_test = load_split_Xy()\n",
    "# Align labels with cache if lengths match\n",
    "if y_test_cache is not None and len(y_test_cache) == n_test:\n",
    "    y_test = y_test_cache  # use cached labels when perfectly aligned\n",
    "\n",
    "# ========= 5) Deep Model Scores (two variants) =========\n",
    "# (a) \"γ version\": S_k = sum_{j>=k} p_j^γ for each threshold k\n",
    "p_deep_gamma = softmax_power(p_test_avg, best_sel.get('gamma', 1.0))\n",
    "scores_deep_gamma = [p_deep_gamma[:, k:].sum(axis=1) for k in range(1, NUM_CLASSES)]\n",
    "\n",
    "# (b) \"γ+Hier4 aware\": k=1..3 use cumulative prob, k=4 uses affine-adjusted ey\n",
    "classes = np.arange(NUM_CLASSES)\n",
    "Ey_gamma = (p_deep_gamma * classes[None, :]).sum(axis=1)\n",
    "Ey_aff   = best_sel.get('a', 1.0) * Ey_gamma + best_sel.get('b', 0.0)\n",
    "scores_deep_hier = []\n",
    "for k in range(1, NUM_CLASSES):\n",
    "    if k < NUM_CLASSES - 1:\n",
    "        scores_deep_hier.append(p_deep_gamma[:, k:].sum(axis=1))  # cumulative probability\n",
    "    else:\n",
    "        scores_deep_hier.append(Ey_aff)  # coherent scalar reflecting Stage-C direction\n",
    "\n",
    "# ========= 6) Train Traditional Baseline Models =========\n",
    "print(\"[INFO] Training RandomForest ...\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced_subsample',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "p_rf_raw = rf.predict_proba(X_test)\n",
    "p_rf = np.zeros((len(X_test), NUM_CLASSES))\n",
    "for j, cls in enumerate(rf.classes_):\n",
    "    p_rf[:, int(cls)] = p_rf_raw[:, j]\n",
    "scores_rf = [p_rf[:, k:].sum(axis=1) for k in range(1, NUM_CLASSES)]\n",
    "\n",
    "# XGBoost (skipped if not available)\n",
    "scores_xgb = None\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    print(\"[INFO] Training XGBoost ...\")\n",
    "    xgb = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=NUM_CLASSES,\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        tree_method='hist',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb.fit(X_train, y_train, eval_metric='mlogloss', verbose=False)\n",
    "    p_xgb_raw = xgb.predict_proba(X_test)\n",
    "    p_xgb = np.zeros((len(X_test), NUM_CLASSES))\n",
    "    for j, cls in enumerate(xgb.classes_):\n",
    "        p_xgb[:, int(cls)] = p_xgb_raw[:, j]\n",
    "    scores_xgb = [p_xgb[:, k:].sum(axis=1) for k in range(1, NUM_CLASSES)]\n",
    "except Exception as e:\n",
    "    print(\"[WARN] XGBoost unavailable, skipped:\", e)\n",
    "\n",
    "# Ordered Logit (skipped if not available)\n",
    "scores_ologit = None\n",
    "try:\n",
    "    from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "    print(\"[INFO] Training Ordered Logit ...\")\n",
    "    ologit = OrderedModel(y_train, X_train, distr='logit')\n",
    "    res = ologit.fit(method='bfgs', maxiter=200, disp=False)\n",
    "    p_ologit = res.model.predict(res.params, exog=X_test, which='prob')  # (n, C)\n",
    "    scores_ologit = [p_ologit[:, k:].sum(axis=1) for k in range(1, NUM_CLASSES)]\n",
    "except Exception as e:\n",
    "    print(\"[WARN] statsmodels OrderedModel unavailable, skipped:\", e)\n",
    "\n",
    "# ========= 7) Compute AUCs and Plot =========\n",
    "panel_labels = [f\"Y≥{k}\" for k in range(1, NUM_CLASSES)]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "macro_table = {}\n",
    "\n",
    "def plot_model(ax_idx, name, scores):\n",
    "    aucs, macro = ordinal_auc_list(y_test, scores)\n",
    "    macro_table[name] = macro\n",
    "    for i, (s_k, A) in enumerate(zip(scores, aucs)):\n",
    "        y_bin = (y_test >= (i + 1)).astype(int)\n",
    "        if len(np.unique(y_bin)) < 2:\n",
    "            continue\n",
    "        fpr, tpr, _ = roc_curve(y_bin, s_k)\n",
    "        axes[i].plot(fpr, tpr, label=f\"{name} (AUC={A:.3f})\")\n",
    "\n",
    "# Plot traditional models first (γ deep, RF, XGB, OLogit)\n",
    "plot_model(axes, \"DeepOrdinal(γ)\", scores_deep_gamma)\n",
    "plot_model(axes, \"RandomForest\",  scores_rf)\n",
    "if scores_xgb is not None:\n",
    "    plot_model(axes, \"XGBoost\", scores_xgb)\n",
    "if scores_ologit is not None:\n",
    "    plot_model(axes, \"OrderedLogit\", scores_ologit)\n",
    "\n",
    "# Overlay \"γ+Hier4 aware\" curve (highlight lift on Y≥4)\n",
    "aucs_hier, macro_hier = ordinal_auc_list(y_test, scores_deep_hier)\n",
    "macro_table[\"DeepOrdinal(γ+Hier4)\"] = macro_hier\n",
    "for i, (s_k, A) in enumerate(zip(scores_deep_hier, aucs_hier)):\n",
    "    y_bin = (y_test >= (i + 1)).astype(int)\n",
    "    if len(np.unique(y_bin)) < 2:\n",
    "        continue\n",
    "    fpr, tpr, _ = roc_curve(y_bin, s_k)\n",
    "    axes[i].plot(fpr, tpr, label=f\"DeepOrdinal(γ+Hier4) (AUC={A:.3f})\", linewidth=2)\n",
    "\n",
    "# Axes & legends\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.plot([0,1], [0,1], '--', color='gray', linewidth=1)\n",
    "    ax.set_title(f\"Ordinal ROC — {lab}\")\n",
    "    ax.set_xlabel(\"FPR\")\n",
    "    ax.set_ylabel(\"TPR\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "out1 = os.path.join(OUT_DIR, \"compare_ordinal_roc_with_hier4.pdf\")\n",
    "plt.savefig(out1, format=\"pdf\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved:\", out1)\n",
    "\n",
    "# Macro average bar chart (including γ+Hier4)\n",
    "plt.figure(figsize=(7,4))\n",
    "names = list(macro_table.keys())\n",
    "vals  = [macro_table[n] for n in names]\n",
    "plt.bar(range(len(names)), vals)\n",
    "plt.xticks(range(len(names)), names, rotation=15)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Mean Ordinal AUC\")\n",
    "plt.title(\"Mean Ordinal AUC across thresholds (Y≥k)\")\n",
    "plt.tight_layout()\n",
    "out2 = os.path.join(OUT_DIR, \"compare_ordinal_auc_bar_with_hier4.pdf\")\n",
    "plt.savefig(out2, format=\"pdf\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved:\", out2)\n",
    "\n",
    "print(\"\\n== Mean Ordinal AUC ==\")\n",
    "for n in names:\n",
    "    print(f\"{n:>22}: {macro_table[n]:.4f}\")\n",
    "\n",
    "print(\"\\n[Completed] All plots saved to directory:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a4de0-c499-4909-898e-eda625c88e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Class-4: Combined PR + Decision Curve Comparison (Deep vs RF/XGB/OrderedLogit) ===\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Optional: train temporarily if p_xgb / p_ologit are missing\n",
    "_need_rf    = 'p_rf' not in globals()\n",
    "_need_xgb   = 'p_xgb' not in globals()\n",
    "_need_ologit = 'p_ologit' not in globals()\n",
    "\n",
    "# -------- Basic Checks --------\n",
    "required = ['p_test_avg', 'best_sel', 'X_train', 'X_test',\n",
    "            'y_train', 'y_test', 'NUM_CLASSES', 'OUT_DIR']\n",
    "missing = [v for v in required if v not in globals()]\n",
    "assert not missing, f\"Missing required variables: {missing}. Please run your deep model code first.\"\n",
    "assert NUM_CLASSES >= 2 and (NUM_CLASSES-1) in np.unique(y_test), \"Label set must include the highest class.\"\n",
    "\n",
    "# -------- Helpers --------\n",
    "def softmax_power(p, gamma):\n",
    "    p = np.clip(p, 1e-8, 1.0)\n",
    "    z = p ** gamma\n",
    "    return z / (z.sum(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def ensure_prob_matrix(raw_probs, raw_classes, C):\n",
    "    \"\"\"Align model output probabilities (n, len(raw_classes)) to (n, C) in order 0..C-1\"\"\"\n",
    "    P = np.zeros((raw_probs.shape[0], C), dtype=float)\n",
    "    for j, c in enumerate(raw_classes):\n",
    "        P[:, int(c)] = raw_probs[:, j]\n",
    "    return P\n",
    "\n",
    "# -------- DeepOrdinal Scores (used for PR / Decision Curve) --------\n",
    "classes = np.arange(NUM_CLASSES)\n",
    "p_deep_gamma = softmax_power(p_test_avg, best_sel['gamma'])\n",
    "s4_deep = p_deep_gamma[:, -1]                  # Deep: P(y=4)\n",
    "y_true4 = (y_test == (NUM_CLASSES-1)).astype(int)\n",
    "prev4 = y_true4.mean()\n",
    "\n",
    "models_probs = {\"DeepOrdinal(γ)\": p_deep_gamma}  # name -> (n, C) probability matrix\n",
    "\n",
    "# -------- RandomForest Probabilities --------\n",
    "if _need_rf:\n",
    "    print(\"[INFO] Training RandomForest to obtain probabilities ...\")\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=None,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced_subsample',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf.fit(X_train, y_train)\n",
    "    _p = rf.predict_proba(X_test)\n",
    "    p_rf = ensure_prob_matrix(_p, rf.classes_, NUM_CLASSES)\n",
    "models_probs[\"RandomForest\"] = p_rf\n",
    "\n",
    "# -------- XGBoost Probabilities --------\n",
    "if _need_xgb:\n",
    "    print(\"[INFO] Training XGBoost to obtain probabilities ...\")\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=NUM_CLASSES,\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        tree_method='hist',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    xgb.fit(X_train, y_train, eval_metric='mlogloss', verbose=False)\n",
    "    _p = xgb.predict_proba(X_test)\n",
    "    p_xgb = ensure_prob_matrix(_p, xgb.classes_, NUM_CLASSES)\n",
    "models_probs[\"XGBoost\"] = p_xgb\n",
    "\n",
    "# -------- Ordered Logit Probabilities --------\n",
    "if _need_ologit:\n",
    "    print(\"[INFO] Training Ordered Logit to obtain probabilities ...\")\n",
    "    from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "    ologit = OrderedModel(y_train, X_train, distr='logit')\n",
    "    res = ologit.fit(method='bfgs', maxiter=200, disp=False)\n",
    "    p_ologit = res.model.predict(res.params, exog=X_test, which='prob')  # (n, C)\n",
    "models_probs[\"OrderedLogit\"] = p_ologit\n",
    "\n",
    "# ================= 1) Class-4 Precision–Recall Curve (All Models in One Plot) =================\n",
    "plt.figure(figsize=(7,5))\n",
    "auprc_table = {}\n",
    "for name, P in models_probs.items():\n",
    "    s4 = P[:, -1]                         # Directly use P(y=4)\n",
    "    prec, rec, _ = precision_recall_curve(y_true4, s4)\n",
    "    au = auc(rec, prec)\n",
    "    auprc_table[name] = au\n",
    "    plt.plot(rec, prec, label=f\"{name} (AUPRC={au:.3f})\")\n",
    "\n",
    "# Plot prevalence reference line (expected precision of random classifier)\n",
    "plt.hlines(prev4, 0, 1, colors='gray', linestyles='--', linewidth=1,\n",
    "           label=f\"prevalence={prev4:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Class-4 Precision–Recall (all models)\")\n",
    "plt.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "out_pr = os.path.join(OUT_DIR, \"class4_pr_all_models.pdf\")\n",
    "plt.savefig(out_pr, format=\"pdf\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved PR plot:\", out_pr)\n",
    "print(\"AUPRC:\", {k: f\"{v:.3f}\" for k, v in auprc_table.items()})\n",
    "\n",
    "# ================= 2) Class-4 Decision Curve (All Models in One Plot) =================\n",
    "def decision_curve(y_true, prob, thresholds=np.linspace(0.01, 0.80, 80)):\n",
    "    y = y_true.astype(int)\n",
    "    N = len(y)\n",
    "    NB = []\n",
    "    for pt in thresholds:\n",
    "        yhat = (prob >= pt).astype(int)\n",
    "        TP = np.sum((yhat == 1) & (y == 1))\n",
    "        FP = np.sum((yhat == 1) & (y == 0))\n",
    "        w = pt / (1.0 - pt)       # cost weight of false positive\n",
    "        nb = TP / N - w * FP / N\n",
    "        NB.append(nb)\n",
    "    return thresholds, np.array(NB)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "ts_ref = np.linspace(0.01, 0.80, 80)\n",
    "\n",
    "# Treat-all / Treat-none reference lines\n",
    "nb_none = np.zeros_like(ts_ref)\n",
    "nb_all  = prev4 - ts_ref / (1 - ts_ref) * (1 - prev4)\n",
    "plt.plot(ts_ref, nb_all,  label=\"Treat-all\",  linestyle=\"--\", linewidth=1)\n",
    "plt.plot(ts_ref, nb_none, label=\"Treat-none\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "for name, P in models_probs.items():\n",
    "    s4 = P[:, -1]\n",
    "    ts, nb = decision_curve(y_true4, s4, thresholds=ts_ref)\n",
    "    plt.plot(ts, nb, label=name)\n",
    "\n",
    "plt.xlabel(\"Threshold probability (class 4)\")\n",
    "plt.ylabel(\"Net Benefit\")\n",
    "plt.title(\"Decision Curve — Class 4 (all models)\")\n",
    "plt.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "out_dc = os.path.join(OUT_DIR, \"class4_decision_curve_all_models.pdf\")\n",
    "plt.savefig(out_dc, format=\"pdf\")\n",
    "plt.close()\n",
    "print(\"[OK] Saved Decision Curve plot:\", out_dc)\n",
    "\n",
    "# ================= 3) Appendix: Suggested Operating Points under PPV Constraints =================\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "def best_at_precision(y_true, prob, min_ppv):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, prob)\n",
    "    idx = np.where(prec[:-1] >= min_ppv)[0]\n",
    "    if idx.size == 0:\n",
    "        return None\n",
    "    i = idx[np.argmax(rec[idx])]\n",
    "    return dict(threshold=float(thr[i]),\n",
    "                precision=float(prec[i]),\n",
    "                recall=float(rec[i]))\n",
    "\n",
    "for ppv in [0.20, 0.25, 0.30, 0.35]:\n",
    "    row = {}\n",
    "    for name, P in models_probs.items():\n",
    "        pick = best_at_precision(y_true4, P[:, -1], ppv)\n",
    "        row[name] = pick\n",
    "    print(f\"\\n[Operating Point Suggestion @ PPV ≥ {ppv:.2f}]\")\n",
    "    for k, v in row.items():\n",
    "        print(f\"{k:>16} :\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809d62b-bca9-4af0-b09a-3e37175a49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Run SHAP Only (Gradually_Increasing, direction=inc), No Training Required.\n",
    "Prerequisite: OUT_DIR already contains trained assets:\n",
    "  - preproc/*.pkl\n",
    "  - indices/*.npy\n",
    "  - ens0.weights.h5\n",
    "  - best_model_params.json\n",
    "  - feature_names.json\n",
    "  - and your data CSV file.\n",
    "Output: Consistency report + SHAP summary / dependence plots for \"consistent proteins\" only.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shap\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "# ===================== Paths (as provided) =====================\n",
    "DATA_PATH = \"./data/extracted_Gradually_Increasing.csv\"\n",
    "OUT_DIR   = \"./results/Gradually_Increasing\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Asset files\n",
    "PREPROC_DIR = os.path.join(OUT_DIR, \"preproc\")\n",
    "IDX_DIR     = os.path.join(OUT_DIR, \"indices\")\n",
    "IMP_P_PKL   = os.path.join(PREPROC_DIR, \"imp_p.pkl\")\n",
    "IMP_C_PKL   = os.path.join(PREPROC_DIR, \"imp_c.pkl\")\n",
    "SC_P_PKL    = os.path.join(PREPROC_DIR, \"sc_p.pkl\")\n",
    "SC_C_PKL    = os.path.join(PREPROC_DIR, \"sc_c.pkl\")\n",
    "IDX_TEST_NPY = os.path.join(IDX_DIR, \"idx_test.npy\")\n",
    "MODEL_PARAMS_JSON = os.path.join(OUT_DIR, \"best_model_params.json\")\n",
    "ENS0_WEIGHTS_H5   = os.path.join(OUT_DIR, \"ens0.weights.h5\")\n",
    "FEATURE_NAMES_JSON = os.path.join(OUT_DIR, \"feature_names.json\")\n",
    "\n",
    "# Fallback slice if feature_names.json columns are not found\n",
    "PROTEIN_SLICE   = slice(9, 63)\n",
    "COVARIATE_SLICE = slice(2, 9)\n",
    "\n",
    "# Task & Plotting Options\n",
    "MONO_MODE_EXPECTED = \"inc\"   # Gradually_Increasing: higher value → worse condition\n",
    "BACKGROUND_K       = 100     # Number of clusters for SHAP background\n",
    "SHAP_SUBSET_N      = 2000    # Number of samples to use for SHAP computation\n",
    "TOPK_DEP_PLOTS     = 30      # Max number of dependence plots for consistent proteins (None = all)\n",
    "FORCE_PLOT_DIRECTION = False # For plotting only: flip sign of inconsistent proteins to unify direction (no effect on saved files)\n",
    "\n",
    "# ===================== Lightweight Model (only for loading weights & forward pass) =====================\n",
    "class OrdinalLDL(tf.keras.Model):\n",
    "    # Note: includes mono_mode for construction compatibility; not used here (forward only)\n",
    "    def __init__(self, input_dim, num_classes, layer_sizes, dropout_rate,\n",
    "                 l2_lambda, protein_indices=None, tau=3.5,\n",
    "                 emd_lambda=1.0, entropy_lambda=0.10, kl_lambda=1.2,\n",
    "                 train_prior=None, mono_mode=None, gaussian_noise_std=0.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.tau = tf.constant(tau, tf.float32)\n",
    "        self.backbone = tf.keras.Sequential(name=\"backbone\")\n",
    "        for s in layer_sizes:\n",
    "            self.backbone.add(tf.keras.layers.Dense(\n",
    "                s, activation='relu',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)))\n",
    "            self.backbone.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "        self.score_head = tf.keras.layers.Dense(1, activation=None,\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(l2_lambda), name=\"score\")\n",
    "        self.alpha_raw = tf.Variable(tf.random.normal([num_classes-1], stddev=0.1),\n",
    "                                     trainable=True, name=\"alpha_raw\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.backbone(inputs, training=training)\n",
    "        score = self.score_head(h)\n",
    "        return score\n",
    "\n",
    "    def get_alphas(self):\n",
    "        inc = tf.nn.softplus(self.alpha_raw) + 1e-6\n",
    "        alpha = tf.cumsum(inc)\n",
    "        alpha = alpha - tf.reduce_mean(alpha)\n",
    "        return alpha\n",
    "\n",
    "# ---- Compute probabilities / expected value from score (SHAP target) ----\n",
    "def probs_from_score(score, alpha, tau):\n",
    "    logits = (score - alpha[tf.newaxis, :]) / tau\n",
    "    probs_gt = tf.sigmoid(logits)\n",
    "    p0 = 1 - probs_gt[:, :1]\n",
    "    p_mid = probs_gt[:, :-1] - probs_gt[:, 1:] if probs_gt.shape[1] > 1 else tf.zeros((tf.shape(score)[0], 0), score.dtype)\n",
    "    plast = probs_gt[:, -1:]\n",
    "    p = tf.concat([p0, p_mid, plast], axis=1)\n",
    "    p = tf.clip_by_value(p, 1e-7, 1.0)\n",
    "    return p / tf.reduce_sum(p, axis=1, keepdims=True)\n",
    "\n",
    "def ey_from_score(score, alpha, tau):\n",
    "    p = probs_from_score(score, alpha, tau)\n",
    "    classes = tf.cast(tf.range(tf.shape(p)[1]), p.dtype)  # 0..C-1\n",
    "    return tf.reduce_sum(p * classes, axis=1, keepdims=True)\n",
    "\n",
    "# ===================== Asset Existence Check =====================\n",
    "need = [IMP_P_PKL, IMP_C_PKL, SC_P_PKL, SC_C_PKL,\n",
    "        IDX_TEST_NPY, MODEL_PARAMS_JSON, ENS0_WEIGHTS_H5, FEATURE_NAMES_JSON]\n",
    "missing = [p for p in need if not os.path.exists(p)]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required training assets for SHAP-only mode:\\n\" + \"\\n\".join(missing) +\n",
    "        \"\\nPlease run the full pipeline script once with FORCE_TRAIN=True to generate them.\"\n",
    "    )\n",
    "\n",
    "# ===================== Load Parameters / Feature Names, Reconstruct X_test =====================\n",
    "params_all = json.load(open(MODEL_PARAMS_JSON, \"r\", encoding=\"utf-8\"))\n",
    "best_params = params_all[\"best_params\"]\n",
    "TAU = float(params_all.get(\"tau\", 3.5))\n",
    "NUM_CLASSES = int(params_all.get(\"num_classes\", 5))\n",
    "\n",
    "feat = json.load(open(FEATURE_NAMES_JSON, \"r\", encoding=\"utf-8\"))\n",
    "protein_names = feat[\"protein\"]\n",
    "covariates_names = feat[\"covariates\"]\n",
    "num_proteins = len(protein_names)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "# Use columns from feature_names.json; fallback to slice if not found\n",
    "try:\n",
    "    prot_idx = [df.columns.get_loc(c) for c in protein_names]\n",
    "    cov_idx  = [df.columns.get_loc(c) for c in covariates_names]\n",
    "    Xp_all = df.iloc[:, prot_idx].values.astype(np.float32)\n",
    "    Xc_all = df.iloc[:, cov_idx ].values.astype(np.float32)\n",
    "except Exception:\n",
    "    Xp_all = df.iloc[:, PROTEIN_SLICE  ].values.astype(np.float32)\n",
    "    Xc_all = df.iloc[:, COVARIATE_SLICE].values.astype(np.float32)\n",
    "\n",
    "idx_test = np.load(IDX_TEST_NPY)\n",
    "Xp_test_raw = Xp_all[idx_test]\n",
    "Xc_test_raw = Xc_all[idx_test]\n",
    "\n",
    "imp_p = joblib.load(IMP_P_PKL)\n",
    "imp_c = joblib.load(IMP_C_PKL)\n",
    "sc_p  = joblib.load(SC_P_PKL)\n",
    "sc_c  = joblib.load(SC_C_PKL)\n",
    "Xp_te = sc_p.transform(imp_p.transform(Xp_test_raw))\n",
    "Xc_te = sc_c.transform(imp_c.transform(Xc_test_raw))\n",
    "X_test_for_shap = np.hstack([Xp_te, Xc_te]).astype(np.float32)\n",
    "print(\"[INFO] X_test_for_shap shape:\", X_test_for_shap.shape)\n",
    "\n",
    "# ===================== Rebuild Model & Load Weights (ens0) =====================\n",
    "tf.keras.backend.clear_session()\n",
    "m0 = OrdinalLDL(\n",
    "    input_dim=X_test_for_shap.shape[1],\n",
    "    num_classes=NUM_CLASSES,\n",
    "    layer_sizes=best_params[\"layers\"],\n",
    "    dropout_rate=best_params[\"dropout\"],\n",
    "    l2_lambda=best_params[\"l2\"],\n",
    "    protein_indices=np.arange(num_proteins),\n",
    "    tau=TAU,\n",
    "    emd_lambda=1.0,\n",
    "    entropy_lambda=0.10,\n",
    "    kl_lambda=1.2,\n",
    "    train_prior=None,\n",
    "    mono_mode=None  # forward pass only, not used in training\n",
    ")\n",
    "m0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params[\"lr\"], clipvalue=1.0))\n",
    "m0.build((None, X_test_for_shap.shape[1]))\n",
    "m0.load_weights(ENS0_WEIGHTS_H5)\n",
    "\n",
    "# ===================== Build E[y] Model & Compute SHAP =====================\n",
    "inp = tf.keras.Input(shape=(X_test_for_shap.shape[1],), dtype=tf.float32)\n",
    "score = m0(inp, training=False)\n",
    "alpha_tf = m0.get_alphas()\n",
    "ey_out = tf.keras.layers.Lambda(lambda s: ey_from_score(s, alpha_tf, TAU),\n",
    "                                name=\"expected_severity\")(score)\n",
    "Ey_model = tf.keras.Model(inputs=inp, outputs=ey_out)\n",
    "\n",
    "# Background samples (k-means clustering)\n",
    "k = min(BACKGROUND_K, len(X_test_for_shap))\n",
    "background = shap.kmeans(X_test_for_shap, k).data\n",
    "n_samples = min(SHAP_SUBSET_N, len(X_test_for_shap))\n",
    "test_subset = X_test_for_shap[:n_samples].astype(np.float32)\n",
    "\n",
    "explainer = shap.GradientExplainer(Ey_model, background)\n",
    "sv = explainer.shap_values(test_subset)\n",
    "if isinstance(sv, list):\n",
    "    sv = sv[0]\n",
    "sv = np.asarray(sv)\n",
    "if sv.ndim == 3 and sv.shape[-1] == 1:\n",
    "    sv = sv[..., 0]\n",
    "assert sv.ndim == 2 and sv.shape[0] == test_subset.shape[0], f\"Unexpected SHAP shape: {sv.shape}\"\n",
    "print(\"[INFO] SHAP values shape:\", sv.shape)\n",
    "\n",
    "# Protein-only SHAP values\n",
    "sv_prot = sv[:, :num_proteins]\n",
    "mean_abs = np.mean(np.abs(sv_prot), axis=0).ravel()\n",
    "pd.DataFrame({\"feature\": protein_names, \"mean_abs_shap_Ey\": mean_abs}) \\\n",
    "  .to_csv(os.path.join(OUT_DIR, \"protein_importance_Ey.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: protein_importance_Ey.csv\")\n",
    "\n",
    "# ===================== Consistency Report (GI expects positive correlation) =====================\n",
    "def shap_dynamic_consistency_report(sv, X, protein_names, num_proteins, out_dir,\n",
    "                                    Ey_model=None, min_bin_size=40, expected=\"inc\"):\n",
    "    Xp  = X[:, :num_proteins]\n",
    "    svp = sv[:, :num_proteins]\n",
    "    rows = []\n",
    "    ey_bins_arr = None\n",
    "    if Ey_model is not None:\n",
    "        Ey_vals = Ey_model.predict(X.astype(np.float32), verbose=0).ravel()\n",
    "        ey_bins = pd.qcut(Ey_vals, q=5, labels=[f\"Q{i+1}\" for i in range(5)])\n",
    "        ey_bins_arr = np.asarray(ey_bins)\n",
    "\n",
    "    for j in range(num_proteins):\n",
    "        x = Xp[:, j]\n",
    "        y = svp[:, j]\n",
    "        rho, rho_p = spearmanr(x, y)\n",
    "        tau, tau_p = kendalltau(x, y)\n",
    "\n",
    "        slope_trim = np.nan\n",
    "        if np.std(x) > 1e-8:\n",
    "            ql, qr = np.quantile(x, [0.1, 0.9])\n",
    "            m = (x >= ql) & (x <= qr)\n",
    "            if np.sum(m) > 1:\n",
    "                slope_trim = np.polyfit(x[m], y[m], 1)[0]\n",
    "\n",
    "        slope_bins = np.nan\n",
    "        try:\n",
    "            bins10 = pd.qcut(x, q=10, duplicates='drop')\n",
    "            dfb = pd.DataFrame({'x': x, 'y': y, 'bin': bins10}).groupby('bin').mean().reset_index()\n",
    "            if len(dfb) > 1:\n",
    "                slope_bins = np.polyfit(dfb['x'].values, dfb['y'].values, 1)[0]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        order = np.argsort(x)\n",
    "        dy = np.diff(y[order])\n",
    "        mvr_up = float(np.mean(dy > 0)) if dy.size > 0 else np.nan\n",
    "\n",
    "        r2_iso = np.nan\n",
    "        try:\n",
    "            ir = IsotonicRegression(increasing=(expected == \"inc\"))\n",
    "            y_iso = ir.fit_transform(x, y)\n",
    "            r2_iso = 1 - np.sum((y - y_iso)**2) / (np.sum((y - np.mean(y))**2) + 1e-12)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        mean_abs_local = float(np.mean(np.abs(y)))\n",
    "\n",
    "        stage_dir_ok_frac = np.nan\n",
    "        if ey_bins_arr is not None:\n",
    "            levels = np.unique(ey_bins_arr)\n",
    "            ok = tot = 0\n",
    "            for lvl in levels:\n",
    "                idx = (ey_bins_arr == lvl)\n",
    "                if np.sum(idx) >= min_bin_size:\n",
    "                    rr, _ = spearmanr(x[idx], y[idx])\n",
    "                    if np.isfinite(rr):\n",
    "                        tot += 1\n",
    "                        if (expected == \"inc\" and rr > 0) or (expected == \"dec\" and rr < 0):\n",
    "                            ok += 1\n",
    "            if tot > 0:\n",
    "                stage_dir_ok_frac = ok / tot\n",
    "\n",
    "        rows.append([\n",
    "            protein_names[j],\n",
    "            mean_abs_local,\n",
    "            rho,\n",
    "            rho_p,\n",
    "            tau,\n",
    "            tau_p,\n",
    "            slope_trim,\n",
    "            slope_bins,\n",
    "            mvr_up,\n",
    "            r2_iso,\n",
    "            stage_dir_ok_frac\n",
    "        ])\n",
    "\n",
    "    cols = [\n",
    "        'feature', 'mean_abs_shap', 'spearman_rho', 'spearman_p',\n",
    "        'kendall_tau', 'kendall_p', 'trimmed_linear_slope', 'binned_slope',\n",
    "        'mvr_up', 'isotonic_R2', 'stage_dir_ok_frac'\n",
    "    ]\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    sign = +1 if expected == \"inc\" else -1\n",
    "    df['direction_ok'] = ((sign * df['spearman_rho'] > 0) & (sign * df['binned_slope'] > 0))\n",
    "    df['strong'] = (\n",
    "        df['direction_ok'] &\n",
    "        (df['spearman_p'] < 0.05) &\n",
    "        (df['mvr_up'] <= 0.40) &\n",
    "        (df['isotonic_R2'] >= 0.10) &\n",
    "        (df['stage_dir_ok_frac'].fillna(1.0) >= 0.60)\n",
    "    )\n",
    "    df['dyn_consistency_score'] = (\n",
    "        (sign * df['spearman_rho'].fillna(0)) *\n",
    "        df['mean_abs_shap'].fillna(0) *\n",
    "        (1 - df['mvr_up'].fillna(0)) *\n",
    "        (df['isotonic_R2'].fillna(0) + 1e-6)\n",
    "    )\n",
    "    df.sort_values(['strong', 'dyn_consistency_score', 'mean_abs_shap'],\n",
    "                   ascending=[False, False, False], inplace=True)\n",
    "\n",
    "    out_path = os.path.join(out_dir, 'shap_dynamic_consistency_report.csv')\n",
    "    df.to_csv(out_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Saved consistency report: {out_path}\")\n",
    "    return df\n",
    "\n",
    "report = shap_dynamic_consistency_report(\n",
    "    sv, test_subset, protein_names, num_proteins,\n",
    "    OUT_DIR, Ey_model=Ey_model, expected=MONO_MODE_EXPECTED\n",
    ")\n",
    "\n",
    "# ===================== Plot Only \"Consistent\" Proteins =====================\n",
    "keep_feats = report.loc[report['direction_ok'], 'feature'].tolist()\n",
    "if not keep_feats:\n",
    "    print(\"[WARN] No proteins passed direction consistency check; falling back to top 20 by importance.\")\n",
    "    keep_idx = list(np.argsort(-mean_abs)[:20])\n",
    "    keep_feats = [protein_names[i] for i in keep_idx]\n",
    "else:\n",
    "    keep_idx = [protein_names.index(f) for f in keep_feats]\n",
    "\n",
    "# Optional: flip sign of inconsistent proteins for plotting only (no effect on saved results)\n",
    "sv_for_plot = sv.copy()\n",
    "if FORCE_PLOT_DIRECTION and MONO_MODE_EXPECTED == \"inc\":\n",
    "    bad_feats = [f for f in protein_names if f not in keep_feats]\n",
    "    bad_idx = [protein_names.index(f) for f in bad_feats]\n",
    "    sv_for_plot[:, bad_idx] *= -1\n",
    "\n",
    "# ---- Summary plot (consistent proteins only) ----\n",
    "plt.figure()\n",
    "shap.summary_plot(\n",
    "    sv_for_plot[:, keep_idx],\n",
    "    test_subset[:, keep_idx],\n",
    "    feature_names=keep_feats,\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"E[y] SHAP Summary (consistent proteins only; right = heavier, red = high value)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"shap_summary_Ey_consistent.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "print(\"Saved: shap_summary_Ey_consistent.pdf (consistent proteins only)\")\n",
    "\n",
    "# ---- Dependence plots (consistent proteins only; limit to TOPK if too many) ----\n",
    "order_by_importance = np.argsort(-mean_abs[keep_idx])\n",
    "dep_list = [keep_idx[i] for i in order_by_importance]\n",
    "if TOPK_DEP_PLOTS is not None:\n",
    "    dep_list = dep_list[:TOPK_DEP_PLOTS]\n",
    "\n",
    "for j in dep_list:\n",
    "    plt.figure()\n",
    "    shap.dependence_plot(\n",
    "        ind=j,\n",
    "        shap_values=sv_for_plot,\n",
    "        features=test_subset,\n",
    "        feature_names=protein_names + covariates_names,\n",
    "        interaction_index=None,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f\"E[y] SHAP Dependence — {protein_names[j]} (right = heavier)\")\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(OUT_DIR, f\"dep_Ey_{protein_names[j]}_consistent.pdf\")\n",
    "    plt.savefig(fname, format=\"pdf\")\n",
    "    plt.close()\n",
    "\n",
    "print(f\"Saved {len(dep_list)} dependence plots to: {OUT_DIR}\")\n",
    "print(\"\\n✅ SHAP analysis completed (plots & report only, no training performed).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
